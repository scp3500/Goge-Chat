import { type Ref, unref, watch } from 'vue';
import { invoke, Channel } from "@tauri-apps/api/core";
import { listen } from "@tauri-apps/api/event";
import type { ChatSession } from '../../api/chat';
import type { PausedChunks } from './state';
import { useConfigStore } from '../config';
import { DEFAULT_SYSTEM_PROMPT } from '../../constants/prompts';
import { Logger } from '../../utils/logger';

interface MessageState {
    activeId: Ref<string | null>;
    currentMessages: Ref<any[]>;
    isGenerating: Ref<boolean>;
    generatingSessionId: Ref<string | null>;
    pausedChunks: Ref<PausedChunks>;
    streamQueue: Ref<string[]>;
    isProcessingQueue: Ref<boolean>;
    tempGeneratedMessage: Ref<{ content: string, reasoning: string } | null>;
    isLoading: Ref<boolean>;
    useReasoning: Ref<boolean>;
    useSearch: Ref<boolean>;
    // activeSession is computed, but compatible with Ref
    activeSession: Ref<ChatSession | null>;
    isChatViewActive: Ref<boolean>;
}

interface MessageActionsDependencies {
    renameSession: (id: string, title: string) => Promise<void>;
}

export function useMessageActions(state: MessageState, deps: MessageActionsDependencies) {
    const {
        activeId,
        currentMessages,
        isGenerating,
        generatingSessionId,
        pausedChunks,
        streamQueue,
        isProcessingQueue,
        tempGeneratedMessage,
        isLoading,
        useReasoning,
        useSearch,
        activeSession,
        isChatViewActive
    } = state;

    const configStore = useConfigStore();
    let isInternalSync = false;

    const processStreamQueue = () => {
        if (isProcessingQueue.value) return;
        isProcessingQueue.value = true;

        const animate = () => {
            // Stop if generation stopped and queue empty
            if (!isGenerating.value && streamQueue.value.length === 0) {
                isProcessingQueue.value = false;
                return;
            }

            if (streamQueue.value.length > 0) {
                const isCurrentSession = activeId.value === generatingSessionId.value;
                const lastMsg = currentMessages.value[currentMessages.value.length - 1];

                // âš¡ï¸ ä¼˜åŒ–ï¼šæ›´æ¿€è¿›çš„æ‰¹é‡å¤„ç†ç­–ç•¥
                // å½“é˜Ÿåˆ—è¾ƒé•¿æ—¶,ä¸€æ¬¡æ€§å¤„ç†æ›´å¤šå­—ç¬¦,å‡å°‘æ¸²æŸ“æ¬¡æ•°
                let charsPerFrame;
                if (streamQueue.value.length > 100) {
                    charsPerFrame = Math.min(50, Math.floor(streamQueue.value.length / 2)); // å¤§é‡ç§¯å‹æ—¶å¿«é€Ÿæ¶ˆåŒ–
                } else if (streamQueue.value.length > 20) {
                    charsPerFrame = Math.min(20, Math.floor(streamQueue.value.length / 3)); // ä¸­ç­‰ç§¯å‹
                } else {
                    charsPerFrame = Math.max(5, Math.floor(streamQueue.value.length / 1.5)); // å°‘é‡æ—¶ä¹Ÿä¿æŒæå¿«é€Ÿåº¦
                }

                const chunk = streamQueue.value.splice(0, charsPerFrame).join('');

                if (isCurrentSession) {
                    if (lastMsg.content === "__LOADING__") lastMsg.content = "";
                    lastMsg.content += chunk;
                }

                if (tempGeneratedMessage.value) {
                    tempGeneratedMessage.value.content += chunk;
                }
            }

            requestAnimationFrame(animate);
        };
        requestAnimationFrame(animate);
    };

    const applyPausedChunks = () => {
        // åªåœ¨æœ‰ç¼“å­˜ä¸”ä»åœ¨ç”Ÿæˆæ—¶æ‰åº”ç”¨
        if (!generatingSessionId.value || !isGenerating.value) {
            return;
        }

        if (generatingSessionId.value === activeId.value && pausedChunks.value.content.length > 0) {
            const lastMsg = currentMessages.value[currentMessages.value.length - 1];
            // ç¡®ä¿æœ€åä¸€æ¡æ¶ˆæ¯å­˜åœ¨ä¸”ç¡®å®æ˜¯ assistant æ¶ˆæ¯
            if (lastMsg && lastMsg.role === 'assistant' && !lastMsg.id) {
                // åº”ç”¨ç¼“å­˜çš„å†…å®¹æ¶ˆæ¯å—
                for (const chunk of pausedChunks.value.content) {
                    lastMsg.content += chunk;
                }
                // åº”ç”¨ç¼“å­˜çš„æ¨ç†æ¶ˆæ¯å—
                for (const chunk of pausedChunks.value.reasoning) {
                    if (!lastMsg.reasoningContent) {
                        lastMsg.reasoningContent = "";
                    }
                    lastMsg.reasoningContent += chunk;
                }
                // æ¸…ç©ºç¼“å­˜
                pausedChunks.value = { content: [], reasoning: [] };
            }
        }
    };

    const setChatViewActive = (active: boolean) => {
        isChatViewActive.value = active;
        // å¦‚æœé‡æ–°æ¿€æ´»èŠå¤©è§†å›¾ï¼Œåº”ç”¨ç¼“å­˜çš„æ¶ˆæ¯å—
        if (active) {
            applyPausedChunks();
        }
    };

    const loadMessages = async (sessionId: string) => {
        // ğŸ”§ ä¿®å¤ï¼šç«‹å³æ¸…ç©ºå½“å‰æ¶ˆæ¯ï¼Œç¡®ä¿æ·¡å…¥æ·¡å‡ºåŠ¨ç”»æœ‰ä¸€ä¸ªå¹²å‡€çš„èµ·ç‚¹
        currentMessages.value = [];
        isLoading.value = true;
        try {
            const history = await invoke<any[]>("get_messages", { sessionId });
            /*
            console.log("ğŸ“¥ Frontend received messages:", {
                count: history?.length || 0,
                messages: history?.map(m => ({
                    role: m.role,
                    contentLen: m.content.length,
                    hasReasoning: !!m.reasoningContent,
                    reasoningLen: m.reasoningContent?.length || 0
                }))
            });
            */

            // åªåœ¨ç¡®è®¤æ˜¯å½“å‰ä¼šè¯æ—¶æ‰æ›´æ–°æ¶ˆæ¯
            if (activeId.value === sessionId) {
                let newMessages = history && history.length > 0
                    ? history.map(m => ({
                        ...m,
                        providerId: m.provider // ğŸŸ¢ Fix: Map DB provider field to frontend providerId
                    }))
                    : [];

                // ğŸ›¡ï¸ æ™ºèƒ½åˆå¹¶ï¼šå¦‚æœå½“å‰æ­£åœ¨ç”Ÿæˆæ¶ˆæ¯ï¼Œå°†æ­£åœ¨ç”Ÿæˆçš„ä¸´æ—¶æ¶ˆæ¯è¿½åŠ åˆ°å†å²è®°å½•å
                if (isGenerating.value && generatingSessionId.value === sessionId && tempGeneratedMessage.value) {
                    // console.log(" [loadMessages] Merging active generation into history");
                    newMessages.push({
                        role: "assistant", // ç¡®ä¿æ˜¯ assistant
                        model: configStore.settings.selectedModelId,
                        providerId: configStore.settings.defaultProviderId, // ğŸŸ¢ Fix
                        content: tempGeneratedMessage.value.content || "",
                        reasoningContent: tempGeneratedMessage.value.reasoning || "",
                        // id ä¸ºç©ºè¡¨ç¤ºæœªä¿å­˜
                    });
                }

                // åŸå­æ€§æ›´æ–°
                currentMessages.value = newMessages;

                // ğŸ”„ åŒæ­¥ä¼šè¯é…ç½®åˆ°å…¨å±€çŠ¶æ€
                const session = activeSession.value;
                if (session) {
                    isInternalSync = true;
                    // å¦‚æœä¼šè¯æœ‰ç‰¹å®šé…ç½®ï¼Œåˆ™ä½¿ç”¨ï¼›å¦åˆ™å›æ»šåˆ°å…¨å±€é»˜è®¤å€¼
                    configStore.settings.defaultPresetId = session.preset_id || configStore.settings.globalPresetId;

                    const targetModelId = session.model_id || configStore.settings.globalModelId;
                    configStore.settings.selectedModelId = targetModelId;

                    // ğŸŸ¢ Fix: auto-detect provider based on model ID
                    // Many users (and the code) forget to save/sync the provider ID, leading to "DeepSeek" default.
                    // We reverse-lookup the provider that owns this model.
                    if (targetModelId) {
                        const allProviders = configStore.settings.providers || [];
                        const ownerProvider = allProviders.find(p =>
                            p.models?.some((m: any) => {
                                const mId = typeof m === 'string' ? m : m.id;
                                return mId === targetModelId;
                            })
                        );

                        if (ownerProvider) {
                            console.log(`[loadMessages] Auto-detected provider for model ${targetModelId}:`, ownerProvider.id);
                            configStore.settings.defaultProviderId = ownerProvider.id;
                        }
                    }

                    // ğŸŸ¢ Fix: Do NOT overwrite global defaultSystemPrompt with session specific prompt.
                    // The global setting should only be changed by the user in Settings.
                    // configStore.settings.defaultSystemPrompt = session.system_prompt || configStore.settings.defaultSystemPrompt;
                    setTimeout(() => { isInternalSync = false; }, 0);
                }
            }
        } catch (err) {
            console.error("è·å–æ¶ˆæ¯å¤±è´¥:", err);
        } finally {
            isLoading.value = false;
        }
    };

    const saveAssistantResponse = async (sessionId: string, content: string, reasoningContent: string | null, fileMetadata: string | null = null, searchMetadata: string | null = null, explicitModelId?: string, explicitProviderId?: string) => {
        /*
        console.log("ğŸ’¾ [SAVE] === START SAVING ===");
        console.log("ğŸ’¾ [SAVE] Content length:", content.length);
        console.log("ğŸ’¾ [SAVE] Reasoning content length:", reasoningContent?.length || 0);
        console.log("ğŸ’¾ [SAVE] File metadata:", fileMetadata);
        console.log("ğŸ’¾ [SAVE] Search metadata:", searchMetadata);
        */

        const targetModel = explicitModelId || configStore.settings.selectedModelId;
        const targetProvider = explicitProviderId || configStore.settings.defaultProviderId;

        const saveParams = {
            sessionId,
            role: "assistant",
            model: targetModel,
            provider: targetProvider, // ğŸŸ¢ Fix: Pass provider to backend
            content,
            reasoningContent,
            fileMetadata,
            searchMetadata
        };

        // console.log("ğŸ’¾ [SAVE] saveParams:", JSON.stringify(saveParams, null, 2));
        // console.log("ğŸ’¾ [SAVE] Invoking save_message...");
        const msgId = await invoke<number>("save_message", saveParams);

        // æ›´æ–°æœ¬åœ°æ¶ˆæ¯çš„ ID
        const lastMsg = currentMessages.value[currentMessages.value.length - 1];
        if (lastMsg && lastMsg.role === 'assistant') {
            lastMsg.id = msgId;
            lastMsg.model = targetModel;
            lastMsg.providerId = targetProvider;
        }
        // console.log("ğŸ’¾ [SAVE] save_message completed");
        // console.log("ğŸ’¾ [SAVE] === END SAVING ===");
    };

    /**
     * âš¡ï¸ æ¶æ„é‡æ„ï¼šéæµå¼æ ‡é¢˜ç”Ÿæˆ (Blocking Mode)
     */
    const autoSummaryTitle = async (sessionId: string) => {
        try {
            console.log(`[Title] å¼€å§‹ä¸ºä¼šè¯ ${sessionId} ç”Ÿæˆæ ‡é¢˜...`);
            const prompt = "è¯·æ€»ç»“ä»¥ä¸Šå¯¹è¯çš„æ ‡é¢˜(8-10å­—)ã€‚ç›´æ¥è¿”å›æ ‡é¢˜æ–‡å­—ï¼Œä¸è¦ä»£ç ï¼Œä¸è¦æ ‡ç‚¹ç¬¦å·ã€‚";

            const filteredMsgs = currentMessages.value.filter(m => m.content && m.content !== "__LOADING__");
            if (filteredMsgs.length < 2) {
                console.log("[Title] æ¶ˆæ¯å¤ªå°‘ï¼Œè·³è¿‡æ€»ç»“");
                return;
            }

            // ç¡®ä¿åŒ…å«ç”¨æˆ·æ¶ˆæ¯ã€‚å¦‚æœç¬¬ä¸€æ¡æ˜¯ systemï¼Œåˆ™ä»ç¬¬ 1 æ¡å¼€å§‹å–ï¼›å¦åˆ™ä»ç¬¬ 0 æ¡å¼€å§‹ã€‚
            const startIdx = filteredMsgs[0]?.role === 'system' ? 1 : 0;
            const summaryMsgs = [
                ...filteredMsgs.slice(startIdx, startIdx + 4).map(m => ({
                    role: m.role,
                    content: m.content
                })),
                { role: "user", content: prompt }
            ];

            const rawTitle = await invoke<string>("generate_title", {
                msg: summaryMsgs,
                explicitProviderId: configStore.settings.defaultProviderId,
                explicitModelId: configStore.settings.selectedModelId
            });

            console.log("[Title] åç«¯è¿”å›åŸå§‹æ ‡é¢˜:", rawTitle);

            // 3. æ¸…ç†æ ‡é¢˜ï¼ˆå»é™¤å¼•å·ã€æ¢è¡Œã€æœ«å°¾æ ‡ç‚¹ï¼‰
            let finalTitle = rawTitle.trim()
                .replace(/^["'â€œâ€Â«ã€Œ]|["'â€œâ€Â»ã€]$/g, "")
                .replace(/[ã€‚ï¼!ï¼Ÿ?]$/, "")
                .trim();

            if (finalTitle.length > 15) {
                finalTitle = finalTitle.substring(0, 15);
            }

            // 5. åº”ç”¨æ›´æ–°
            const currentSession = activeSession.value;
            const oldTitle = currentSession?.title || "";

            if (finalTitle && finalTitle.length > 0 && finalTitle !== oldTitle && !["æ–°å¯¹è¯", "é»˜è®¤ä¼šè¯", "New Chat"].includes(finalTitle)) {
                console.log(`[Title] æ ‡é¢˜å˜æ›´: "${oldTitle}" -> "${finalTitle}"`);
                await deps.renameSession(sessionId, finalTitle);
            } else {
                console.log("[Title] æ ‡é¢˜æ— å˜åŒ–æˆ– AI è¿”å›äº†é»˜è®¤å€¼ï¼Œè·³è¿‡æ›´æ–°");
            }

        } catch (e) {
            console.error("è‡ªåŠ¨æ€»ç»“æ ‡é¢˜å¤±è´¥:", e);
        }
    };

    const sendMessage = async (text: string, fileMetadata: string | null = null, provider: string = 'all', mentions: any[] = []) => {
        // å¦‚æœ text ä¸ºç©ºï¼Œåˆ™è¡¨ç¤ºâ€œåŸºäºå½“å‰å†å²é‡æ–°ç”Ÿæˆâ€ï¼Œæ­¤æ—¶è¦æ±‚å¿…é¡»æœ‰å†å²æ¶ˆæ¯
        const isRegeneratingFromHistory = text.trim() === "" && currentMessages.value.length > 0;

        if (!activeId.value || isGenerating.value) return;
        if (!isRegeneratingFromHistory && !text.trim()) return;

        const startTime = Date.now();
        Logger.stage('Chat Sequence Started');

        const sessionId = activeId.value;
        const currentMode = configStore.settings.chatMode?.enabled ? "Social" : "Standard";

        isGenerating.value = true;

        // è®¾ç½®æ­£åœ¨ç”Ÿæˆæ¶ˆæ¯çš„ä¼šè¯ ID å¹¶æ¸…ç©ºä¹‹å‰çš„ç¼“å­˜
        generatingSessionId.value = sessionId;
        pausedChunks.value = { content: [], reasoning: [] };
        streamQueue.value = []; // Clear queue at start

        const isStreamEnabled = configStore.settings.chatMode?.enabled
            ? configStore.settings.chatMode.enableStream
            : configStore.settings.enableStream;

        try {
            // await invoke("reset_ai_generation"); // Moved inside loop

            if (!isRegeneratingFromHistory) {
                const msgId = await invoke<number>("save_message", {
                    sessionId,
                    role: "user",
                    content: text,
                    reasoningContent: null,
                    fileMetadata: fileMetadata,
                    searchMetadata: null
                });

                // æ·»åŠ åˆ°å½“å‰æ¶ˆæ¯åˆ—è¡¨
                currentMessages.value.push({
                    id: msgId,
                    role: "user",
                    content: text,
                    reasoningContent: null,
                    fileMetadata: fileMetadata,
                    searchMetadata: null
                });
            }

            // --- ç¡®å®šè¦è°ƒç”¨çš„æ¨¡å‹åˆ—è¡¨ ---
            let modelsToCall = mentions && mentions.length > 0
                ? mentions
                : [{ id: configStore.settings.selectedModelId, providerId: configStore.settings.defaultProviderId }];

            // ğŸ›¡ï¸ Safety filter
            modelsToCall = modelsToCall.filter(m => m && m.id);

            if (modelsToCall.length === 0) {
                modelsToCall = [{ id: configStore.settings.selectedModelId, providerId: configStore.settings.defaultProviderId }];
            }

            Logger.info(`Models to call (Count ${modelsToCall.length}): ${modelsToCall.map(m => m.id).join(', ')}`);

            // ğŸ”„ é‡ç½®ä¸­æ–­æ ‡å¿—ä½
            await invoke("reset_ai_generation");

            // --- ğŸš€ å¹¶è¡Œå‘èµ·æ‰€æœ‰æ¨¡å‹çš„è¯·æ±‚ ---
            const modelTasks = modelsToCall.map(async (modelInfo, index) => {
                const currentModelId = modelInfo.id;
                const currentProviderId = modelInfo.providerId;

                // 1. åœ¨ UI ä¸­ä¸ºæ¯ä¸ªæ¨¡å‹é¢„ç•™ä¸€ä¸ªæ¶ˆæ¯ä½ (ä½¿ç”¨ä¸åŒçš„å¼•ç”¨)
                const messageObj = {
                    role: "assistant",
                    model: currentModelId,
                    providerId: currentProviderId,
                    content: '__LOADING__',
                    reasoningContent: '',
                    fileMetadata: null,
                    searchMetadata: null,
                    id: undefined as number | undefined
                };
                currentMessages.value.push(messageObj);
                const messageRef = currentMessages.value[currentMessages.value.length - 1];

                const onEvent = new Channel<string>();
                let aiFullContent = '';
                let ttft = 0;
                let searchStartTime = 0;
                let memoryStartTime = 0;

                // ç›‘å¬æœç´¢çŠ¶æ€ (æ³¨æ„ï¼šåç«¯äº‹ä»¶æ˜¯å¹¿æ’­çš„ï¼Œè¿™é‡Œéœ€è¦åŒºåˆ† ID å—ï¼Ÿ
                // ç›®å‰åç«¯ handle_search_parallel æ˜¯åœ¨ ask_ai å†…éƒ¨çš„ï¼Œ
                // ç”±äºæˆ‘ä»¬å¼€äº†å¤šä¸ª ask_ai è°ƒç”¨ï¼Œä¼šæœ‰å¤šä¸ª search-status äº‹ä»¶ã€‚
                // æš‚æ—¶ç›‘å¬å…¨å±€ï¼Œä½†åªæ›´æ–°å½“å‰æ¶ˆæ¯å¼•ç”¨çš„çŠ¶æ€ã€‚)
                const unlistenSearch = await listen('search-status', (event: any) => {
                    const payload = event.payload;
                    if (payload.status === 'searching') {
                        searchStartTime = Date.now();
                        messageRef.searchStatus = 'searching';
                        messageRef.searchQuery = payload.query;
                    } else if (payload.status === 'done') {
                        messageRef.searchStatus = 'done';
                        messageRef.searchMetadata = JSON.stringify(payload.results);
                    } else if (payload.status === 'error') {
                        messageRef.searchStatus = 'error';
                    }
                });

                const unlistenMemory = await listen('memory-status', (event: any) => {
                    const payload = event.payload;
                    if (payload.status === 'searching') {
                        memoryStartTime = Date.now();
                    } else if (payload.status === 'done') {
                        // Logger.success(`Memory for ${currentModelId} done`);
                    }
                });

                onEvent.onmessage = (data) => {
                    if (!isGenerating.value) return;

                    if (ttft === 0 && (data.startsWith("c:") || data.startsWith("r:"))) {
                        ttft = Date.now() - startTime;
                        Logger.timing(`TTFT for ${currentModelId}`, ttft);
                    }

                    if (data.startsWith("c:")) {
                        const content = data.substring(2);
                        aiFullContent += content;

                        // âš¡ï¸ ä¼˜åŒ–ï¼šé›¶å»¶è¿Ÿå‘ˆç°é€»è¾‘
                        const currentText = messageRef.content === "__LOADING__" ? "" : messageRef.content;

                        // 1. å¦‚æœæ˜¯å‰ 40 ä¸ªå­—ç¬¦ï¼ˆçº¦ 5-10 ä¸ª Tokenï¼‰ï¼Œç›´æ¥â€œé€ä¼ â€æ˜¾ç¤ºï¼Œä¸è¿›é˜Ÿåˆ—
                        // è¿™æ ·ç”¨æˆ·èƒ½åœ¨ç½‘ç»œåŒ…åˆ°è¾¾çš„ä¸€ç¬é—´çœ‹åˆ°é¦–ä¸ªå­—ï¼Œæ— éœ€ç­‰å¾…ä¸‹ä¸€å¸§ requestAnimationFrame
                        if (currentText.length < 40) {
                            messageRef.content = currentText + content;
                        } else {
                            // 2. ä¹‹åçš„å­—ç¬¦ç›´æ¥è¿½åŠ ï¼ˆç›®å‰å¤šæ¨¡å‹æ¨¡å¼ä¸‹ï¼Œç›´æ¥è¿½åŠ æ˜¯æœ€é«˜æ•ˆçš„ï¼Œ
                            // ä¸”å› ä¸ºæˆ‘ä»¬å¼€å¯äº†é«˜é¢‘è¿æ¥ä¼˜åŒ–ï¼Œæ•°æ®åˆ°è¾¾é¢‘ç‡å·²ç»è‚‰çœ¼å¯è§åœ°å¹³æ»‘äº†ï¼‰
                            messageRef.content = currentText + content;
                        }
                    }
                    else if (data.startsWith("r:")) {
                        const content = data.substring(2);
                        if (!messageRef.reasoningContent) messageRef.reasoningContent = "";
                        messageRef.reasoningContent += content;
                    }
                };

                // å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
                const msgsToSend = currentMessages.value
                    .filter(m => m.role !== 'assistant' || m.id !== undefined) // åªåŒ…å«å·²ä¿å­˜çš„å†å²åŠ©æ‰‹æ¶ˆæ¯
                    .map((m) => ({
                        role: m.role,
                        content: m.content,
                        reasoningContent: m.reasoningContent,
                        fileMetadata: m.fileMetadata,
                        searchMetadata: m.searchMetadata,
                        mode: currentMode,
                        roleId: "default"
                    }));

                // æ³¨å…¥ç³»ç»Ÿæç¤ºè¯
                const activePreset = configStore.settings.presets.find(p => p.id === configStore.settings.defaultPresetId);
                let presetPrompt = activePreset?.id === 'default_preset' ? "" : activePreset?.systemPrompt;
                const finalSystemPrompt = presetPrompt || configStore.settings.defaultSystemPrompt || DEFAULT_SYSTEM_PROMPT;

                if (msgsToSend.length === 0 || msgsToSend[0].role !== 'system') {
                    msgsToSend.unshift({ role: 'system', content: finalSystemPrompt, reasoningContent: null, fileMetadata: null, searchMetadata: null, mode: currentMode, roleId: "default" });
                }

                // æ³¨å…¥æ¨ç†æ ‡è®°
                if (useReasoning.value) {
                    const lastUser = [...msgsToSend].reverse().find(m => m.role === 'user');
                    if (lastUser) lastUser.content = `[REASON]${lastUser.content}`;
                }

                // æ‰§è¡Œè°ƒç”¨
                try {
                    await invoke("ask_ai", {
                        msg: msgsToSend,
                        onEvent,
                        temperature: activePreset?.temperature,
                        max_tokens: activePreset?.maxTokens,
                        explicitProviderId: currentProviderId,
                        explicitModelId: currentModelId,
                        stream: isStreamEnabled
                    });

                    if (messageRef.content === '__LOADING__') {
                        messageRef.content = aiFullContent || "";
                    }

                    // ä¿å­˜åˆ°æ•°æ®åº“
                    await saveAssistantResponse(sessionId, aiFullContent, messageRef.reasoningContent || null, null, messageRef.searchMetadata || null, currentModelId, currentProviderId);
                } catch (e: any) {
                    console.error(`Model ${currentModelId} failed:`, e);
                    messageRef.content = "";
                    messageRef.error = { message: e.message || String(e), type: 'error' };
                } finally {
                    unlistenSearch();
                    unlistenMemory();
                }
            });

            await Promise.all(modelTasks);

            // è‡ªåŠ¨æ€»ç»“æ ‡é¢˜
            const msgCount = currentMessages.value.filter(m => m.content && m.content !== "__LOADING__").length;
            const isDefaultTitle = !activeSession.value?.title ||
                ["æ–°å¯¹è¯", "é»˜è®¤ä¼šè¯", "New Chat", "é»˜è®¤å¯¹è¯"].includes(activeSession.value?.title);

            if (msgCount >= 2 && isDefaultTitle) {
                autoSummaryTitle(sessionId);
            }
        } catch (error: any) {
            console.error("å¯¹è¯å¤±è´¥:", error);
            const lastMsg = currentMessages.value[currentMessages.value.length - 1];
            if (lastMsg && lastMsg.role === 'assistant' && lastMsg.content === '__LOADING__') {
                let errorMsg = error.message || String(error);
                if (errorMsg.includes('timed out')) errorMsg = 'è¯·æ±‚è¶…æ—¶ (60s)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•ã€‚';
                else if (errorMsg.includes('quota') || errorMsg.includes('429')) errorMsg = 'è¯·æ±‚é€Ÿç‡è¶…è¿‡é™åˆ¶æˆ–é…é¢ä¸è¶³ã€‚';

                lastMsg.content = '';
                lastMsg.error = { message: errorMsg, type: 'error' };
            }
        } finally {
            isGenerating.value = false;
            pausedChunks.value = { content: [], reasoning: [] };
        }
    };

    const stopGeneration = async () => {
        isGenerating.value = false;
        // æ¸…ç©ºç”Ÿæˆä¼šè¯çŠ¶æ€å’Œç¼“å­˜
        generatingSessionId.value = null;
        pausedChunks.value = { content: [], reasoning: [] };
        streamQueue.value = []; // Clear queue on stop
        try { await invoke("stop_ai_generation"); } catch (err) { console.error(err); }
    };

    const clearMessages = async (sessionId: string) => {
        try {
            // 1. è°ƒç”¨ Rust åç«¯æ¸…ç©ºæ¶ˆæ¯
            await invoke("clear_messages", { sessionId });

            // 2. å¦‚æœæ˜¯å½“å‰ä¼šè¯ï¼Œæ¸…ç©ºæœ¬åœ°æ˜¾ç¤º
            if (activeId.value === sessionId) {
                currentMessages.value = [{ role: "system", content: "ä½ æ˜¯ä¸€ä¸ªç®€æ´ä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚" }];
            }
        } catch (e) {
            console.error("æ¸…ç©ºæ¶ˆæ¯å¤±è´¥:", e);
        }
    };

    const deleteMessageAction = async (messageId: number | undefined, index: number) => {
        try {
            if (messageId) {
                await invoke("delete_message", { messageId });
            }
            currentMessages.value.splice(index, 1);
        } catch (e) {
            console.error("åˆ é™¤æ¶ˆæ¯å¤±è´¥:", e);
        }
    };

    const editMessageAction = async (messageId: number | undefined, index: number, newContent: string) => {
        try {
            if (!activeId.value) return;

            // 1. æ›´æ–°æ•°æ®åº“ä¸­è¯¥æ¡æ¶ˆæ¯çš„å†…å®¹
            if (messageId) {
                await invoke("update_message", { messageId, content: newContent });

                // 2. åˆ é™¤è¯¥æ¡æ¶ˆæ¯ä¹‹åçš„æ‰€æœ‰æ¶ˆæ¯
                await invoke("delete_messages_after", {
                    sessionId: activeId.value,
                    messageId: messageId
                });
            }

            // 3. æ›´æ–°æœ¬åœ°çŠ¶æ€ï¼šä¿®æ”¹å†…å®¹å¹¶æˆªæ–­åˆ—è¡¨
            currentMessages.value[index].content = newContent;
            currentMessages.value = currentMessages.value.slice(0, index + 1);

            // 4. é‡æ–°è§¦å‘ AI å›ç­”
            await sendMessage(""); // ä¼ ç©ºå­—ç¬¦ä¸²è§¦å‘é€»è¾‘
        } catch (e) {
            console.error("ç¼–è¾‘æ¶ˆæ¯å¤±è´¥:", e);
        }
    };

    const regenerateAction = async (index: number) => {
        try {
            if (!activeId.value) return;

            // 1. å¦‚æœå½“å‰ç‚¹å‡»çš„æ˜¯ assistant æ¶ˆæ¯ï¼Œå…ˆåˆ é™¤å®ƒ
            const msg = currentMessages.value[index];
            if (msg.role === 'assistant' && msg.id) {
                await invoke("delete_message", { messageId: msg.id });
                currentMessages.value.splice(index, 1);
            }

            // 2. é‡æ–°è§¦å‘ AI å›ç­” (åŸºäºæœ€åä¸€æ¡ user æ¶ˆæ¯)
            await sendMessage("");
        } catch (e) {
            console.error("é‡æ–°ç”Ÿæˆå¤±è´¥:", e);
        }
    };
    // ğŸ•µï¸ å®æ—¶åŒæ­¥ç›‘å¬ï¼šå½“ç”¨æˆ·åœ¨ UI ä¿®æ”¹æ¨¡å‹/é¢„è®¾æ—¶ï¼Œå¦‚æœå½“å‰æœ‰æ´»è·ƒä¼šè¯ï¼Œç«‹å³æŒä¹…åŒ–
    watch(
        [() => configStore.settings.selectedModelId, () => configStore.settings.defaultPresetId],
        async ([newModel, newPreset]) => {
            if (isInternalSync || !activeId.value) return;

            console.log("ğŸ› ï¸ æ£€æµ‹åˆ° UI é…ç½®å˜æ›´ï¼Œæ­£åœ¨åŒæ­¥è‡³ä¼šè¯:", activeId.value);
            try {
                await invoke("update_session_config", {
                    id: activeId.value,
                    presetId: newPreset,
                    modelId: newModel,
                    systemPrompt: activeSession.value?.system_prompt || null
                });

                // åŒæ­¥æœ¬åœ°å†…å­˜çŠ¶æ€
                if (activeSession.value) {
                    activeSession.value.preset_id = newPreset;
                    activeSession.value.model_id = newModel;
                }
            } catch (e) {
                console.error("åŒæ­¥ä¼šè¯é…ç½®å¤±è´¥:", e);
            }
        }
    );

    return {
        processStreamQueue,
        applyPausedChunks,
        setChatViewActive,
        loadMessages,
        sendMessage,
        stopGeneration,
        clearMessages,
        deleteMessageAction,
        editMessageAction,
        regenerateAction,
        saveAssistantResponse,
        autoSummaryTitle
    };
}
