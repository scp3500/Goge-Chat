import { type Ref, unref, watch } from 'vue';
import { invoke, Channel } from "@tauri-apps/api/core";
import { listen } from "@tauri-apps/api/event";
import type { ChatSession } from '../../api/chat';
import type { PausedChunks } from './state';
import { useConfigStore } from '../config';
import { DEFAULT_SYSTEM_PROMPT } from '../../constants/prompts';
import { Logger } from '../../utils/logger';

interface MessageState {
    activeId: Ref<string | null>;
    currentMessages: Ref<any[]>;
    isGenerating: Ref<boolean>;
    generatingSessionId: Ref<string | null>;
    pausedChunks: Ref<PausedChunks>;
    streamQueue: Ref<string[]>;
    isProcessingQueue: Ref<boolean>;
    tempGeneratedMessage: Ref<{ content: string, reasoning: string } | null>;
    isLoading: Ref<boolean>;
    useReasoning: Ref<boolean>;
    useSearch: Ref<boolean>;
    // activeSession is computed, but compatible with Ref
    activeSession: Ref<ChatSession | null>;
    isChatViewActive: Ref<boolean>;
}

interface MessageActionsDependencies {
    renameSession: (id: string, title: string) => Promise<void>;
}

export function useMessageActions(state: MessageState, deps: MessageActionsDependencies) {
    const {
        activeId,
        currentMessages,
        isGenerating,
        generatingSessionId,
        pausedChunks,
        streamQueue,
        isProcessingQueue,
        tempGeneratedMessage,
        isLoading,
        useReasoning,
        useSearch,
        activeSession,
        isChatViewActive
    } = state;

    const configStore = useConfigStore();
    let isInternalSync = false;

    const processStreamQueue = () => {
        if (isProcessingQueue.value) return;
        isProcessingQueue.value = true;

        const animate = () => {
            // Stop if generation stopped and queue empty
            if (!isGenerating.value && streamQueue.value.length === 0) {
                isProcessingQueue.value = false;
                return;
            }

            if (streamQueue.value.length > 0) {
                const isCurrentSession = activeId.value === generatingSessionId.value;
                const lastMsg = currentMessages.value[currentMessages.value.length - 1];

                // âš¡ï¸ Adaptive Speed Control
                const charsPerFrame = Math.max(1, Math.floor(streamQueue.value.length / 4));
                const chunk = streamQueue.value.splice(0, charsPerFrame).join('');

                if (isCurrentSession) {
                    if (lastMsg.content === "__LOADING__") lastMsg.content = "";
                    lastMsg.content += chunk;
                }

                if (tempGeneratedMessage.value) {
                    tempGeneratedMessage.value.content += chunk;
                }
            }

            requestAnimationFrame(animate);
        };
        requestAnimationFrame(animate);
    };

    const applyPausedChunks = () => {
        // åªåœ¨æœ‰ç¼“å­˜ä¸”ä»åœ¨ç”Ÿæˆæ—¶æ‰åº”ç”¨
        if (!generatingSessionId.value || !isGenerating.value) {
            return;
        }

        if (generatingSessionId.value === activeId.value && pausedChunks.value.content.length > 0) {
            const lastMsg = currentMessages.value[currentMessages.value.length - 1];
            // ç¡®ä¿æœ€åä¸€æ¡æ¶ˆæ¯å­˜åœ¨ä¸”ç¡®å®æ˜¯ assistant æ¶ˆæ¯
            if (lastMsg && lastMsg.role === 'assistant' && !lastMsg.id) {
                // åº”ç”¨ç¼“å­˜çš„å†…å®¹æ¶ˆæ¯å—
                for (const chunk of pausedChunks.value.content) {
                    lastMsg.content += chunk;
                }
                // åº”ç”¨ç¼“å­˜çš„æ¨ç†æ¶ˆæ¯å—
                for (const chunk of pausedChunks.value.reasoning) {
                    if (!lastMsg.reasoningContent) {
                        lastMsg.reasoningContent = "";
                    }
                    lastMsg.reasoningContent += chunk;
                }
                // æ¸…ç©ºç¼“å­˜
                pausedChunks.value = { content: [], reasoning: [] };
            }
        }
    };

    const setChatViewActive = (active: boolean) => {
        isChatViewActive.value = active;
        // å¦‚æœé‡æ–°æ¿€æ´»èŠå¤©è§†å›¾ï¼Œåº”ç”¨ç¼“å­˜çš„æ¶ˆæ¯å—
        if (active) {
            applyPausedChunks();
        }
    };

    const loadMessages = async (sessionId: string) => {
        // ğŸ”§ ä¿®å¤ï¼šç«‹å³æ¸…ç©ºå½“å‰æ¶ˆæ¯ï¼Œç¡®ä¿æ·¡å…¥æ·¡å‡ºåŠ¨ç”»æœ‰ä¸€ä¸ªå¹²å‡€çš„èµ·ç‚¹
        currentMessages.value = [];
        isLoading.value = true;
        try {
            const history = await invoke<any[]>("get_messages", { sessionId });
            /*
            console.log("ğŸ“¥ Frontend received messages:", {
                count: history?.length || 0,
                messages: history?.map(m => ({
                    role: m.role,
                    contentLen: m.content.length,
                    hasReasoning: !!m.reasoningContent,
                    reasoningLen: m.reasoningContent?.length || 0
                }))
            });
            */

            // åªåœ¨ç¡®è®¤æ˜¯å½“å‰ä¼šè¯æ—¶æ‰æ›´æ–°æ¶ˆæ¯
            if (activeId.value === sessionId) {
                let newMessages = history && history.length > 0
                    ? history.map(m => ({
                        ...m,
                        providerId: m.provider // ğŸŸ¢ Fix: Map DB provider field to frontend providerId
                    }))
                    : [];

                // ğŸ›¡ï¸ æ™ºèƒ½åˆå¹¶ï¼šå¦‚æœå½“å‰æ­£åœ¨ç”Ÿæˆæ¶ˆæ¯ï¼Œå°†æ­£åœ¨ç”Ÿæˆçš„ä¸´æ—¶æ¶ˆæ¯è¿½åŠ åˆ°å†å²è®°å½•å
                if (isGenerating.value && generatingSessionId.value === sessionId && tempGeneratedMessage.value) {
                    // console.log(" [loadMessages] Merging active generation into history");
                    newMessages.push({
                        role: "assistant", // ç¡®ä¿æ˜¯ assistant
                        model: configStore.settings.selectedModelId,
                        providerId: configStore.settings.defaultProviderId, // ğŸŸ¢ Fix
                        content: tempGeneratedMessage.value.content || "",
                        reasoningContent: tempGeneratedMessage.value.reasoning || "",
                        // id ä¸ºç©ºè¡¨ç¤ºæœªä¿å­˜
                    });
                }

                // åŸå­æ€§æ›´æ–°
                currentMessages.value = newMessages;

                // ğŸ”„ åŒæ­¥ä¼šè¯é…ç½®åˆ°å…¨å±€çŠ¶æ€
                const session = activeSession.value;
                if (session) {
                    isInternalSync = true;
                    // å¦‚æœä¼šè¯æœ‰ç‰¹å®šé…ç½®ï¼Œåˆ™ä½¿ç”¨ï¼›å¦åˆ™å›æ»šåˆ°å…¨å±€é»˜è®¤å€¼
                    configStore.settings.defaultPresetId = session.preset_id || configStore.settings.globalPresetId;

                    const targetModelId = session.model_id || configStore.settings.globalModelId;
                    configStore.settings.selectedModelId = targetModelId;

                    // ğŸŸ¢ Fix: auto-detect provider based on model ID
                    // Many users (and the code) forget to save/sync the provider ID, leading to "DeepSeek" default.
                    // We reverse-lookup the provider that owns this model.
                    if (targetModelId) {
                        const allProviders = configStore.settings.providers || [];
                        const ownerProvider = allProviders.find(p =>
                            p.models?.some((m: any) => {
                                const mId = typeof m === 'string' ? m : m.id;
                                return mId === targetModelId;
                            })
                        );

                        if (ownerProvider) {
                            console.log(`[loadMessages] Auto-detected provider for model ${targetModelId}:`, ownerProvider.id);
                            configStore.settings.defaultProviderId = ownerProvider.id;
                        }
                    }

                    // ğŸŸ¢ Fix: Do NOT overwrite global defaultSystemPrompt with session specific prompt.
                    // The global setting should only be changed by the user in Settings.
                    // configStore.settings.defaultSystemPrompt = session.system_prompt || configStore.settings.defaultSystemPrompt;
                    setTimeout(() => { isInternalSync = false; }, 0);
                }
            }
        } catch (err) {
            console.error("è·å–æ¶ˆæ¯å¤±è´¥:", err);
        } finally {
            isLoading.value = false;
        }
    };

    const saveAssistantResponse = async (sessionId: string, content: string, reasoningContent: string | null, fileMetadata: string | null = null, searchMetadata: string | null = null) => {
        /*
        console.log("ğŸ’¾ [SAVE] === START SAVING ===");
        console.log("ğŸ’¾ [SAVE] Content length:", content.length);
        console.log("ğŸ’¾ [SAVE] Reasoning content length:", reasoningContent?.length || 0);
        console.log("ğŸ’¾ [SAVE] File metadata:", fileMetadata);
        console.log("ğŸ’¾ [SAVE] Search metadata:", searchMetadata);
        */

        const saveParams = {
            sessionId,
            role: "assistant",
            model: configStore.settings.selectedModelId,
            provider: configStore.settings.defaultProviderId, // ğŸŸ¢ Fix: Pass provider to backend
            content,
            reasoningContent,
            fileMetadata,
            searchMetadata
        };

        // console.log("ğŸ’¾ [SAVE] saveParams:", JSON.stringify(saveParams, null, 2));
        // console.log("ğŸ’¾ [SAVE] Invoking save_message...");
        const msgId = await invoke<number>("save_message", saveParams);

        // æ›´æ–°æœ¬åœ°æ¶ˆæ¯çš„ ID
        const lastMsg = currentMessages.value[currentMessages.value.length - 1];
        if (lastMsg && lastMsg.role === 'assistant') {
            lastMsg.id = msgId;
            lastMsg.model = configStore.settings.selectedModelId;
        }
        // console.log("ğŸ’¾ [SAVE] save_message completed");
        // console.log("ğŸ’¾ [SAVE] === END SAVING ===");
    };

    /**
     * âš¡ï¸ æ¶æ„é‡æ„ï¼šéæµå¼æ ‡é¢˜ç”Ÿæˆ (Blocking Mode)
     */
    const autoSummaryTitle = async (sessionId: string) => {
        try {
            console.log(`[Title] å¼€å§‹ä¸ºä¼šè¯ ${sessionId} ç”Ÿæˆæ ‡é¢˜...`);
            const prompt = "è¯·æ€»ç»“ä»¥ä¸Šå¯¹è¯çš„æ ‡é¢˜(8-10å­—)ã€‚ç›´æ¥è¿”å›æ ‡é¢˜æ–‡å­—ï¼Œä¸è¦ä»£ç ï¼Œä¸è¦æ ‡ç‚¹ç¬¦å·ã€‚";

            const filteredMsgs = currentMessages.value.filter(m => m.content && m.content !== "__LOADING__");
            if (filteredMsgs.length < 2) {
                console.log("[Title] æ¶ˆæ¯å¤ªå°‘ï¼Œè·³è¿‡æ€»ç»“");
                return;
            }

            // ç¡®ä¿åŒ…å«ç”¨æˆ·æ¶ˆæ¯ã€‚å¦‚æœç¬¬ä¸€æ¡æ˜¯ systemï¼Œåˆ™ä»ç¬¬ 1 æ¡å¼€å§‹å–ï¼›å¦åˆ™ä»ç¬¬ 0 æ¡å¼€å§‹ã€‚
            const startIdx = filteredMsgs[0]?.role === 'system' ? 1 : 0;
            const summaryMsgs = [
                ...filteredMsgs.slice(startIdx, startIdx + 4).map(m => ({
                    role: m.role,
                    content: m.content
                })),
                { role: "user", content: prompt }
            ];

            const rawTitle = await invoke<string>("generate_title", {
                msg: summaryMsgs,
                explicitProviderId: configStore.settings.defaultProviderId,
                explicitModelId: configStore.settings.selectedModelId
            });

            console.log("[Title] åç«¯è¿”å›åŸå§‹æ ‡é¢˜:", rawTitle);

            // 3. æ¸…ç†æ ‡é¢˜ï¼ˆå»é™¤å¼•å·ã€æ¢è¡Œã€æœ«å°¾æ ‡ç‚¹ï¼‰
            let finalTitle = rawTitle.trim()
                .replace(/^["'â€œâ€Â«ã€Œ]|["'â€œâ€Â»ã€]$/g, "")
                .replace(/[ã€‚ï¼!ï¼Ÿ?]$/, "")
                .trim();

            if (finalTitle.length > 15) {
                finalTitle = finalTitle.substring(0, 15);
            }

            // 5. åº”ç”¨æ›´æ–°
            const currentSession = activeSession.value;
            const oldTitle = currentSession?.title || "";

            if (finalTitle && finalTitle.length > 0 && finalTitle !== oldTitle && !["æ–°å¯¹è¯", "é»˜è®¤ä¼šè¯", "New Chat"].includes(finalTitle)) {
                console.log(`[Title] æ ‡é¢˜å˜æ›´: "${oldTitle}" -> "${finalTitle}"`);
                await deps.renameSession(sessionId, finalTitle);
            } else {
                console.log("[Title] æ ‡é¢˜æ— å˜åŒ–æˆ– AI è¿”å›äº†é»˜è®¤å€¼ï¼Œè·³è¿‡æ›´æ–°");
            }

        } catch (e) {
            console.error("è‡ªåŠ¨æ€»ç»“æ ‡é¢˜å¤±è´¥:", e);
        }
    };

    const sendMessage = async (text: string, fileMetadata: string | null = null, provider: string = 'all') => {
        // å¦‚æœ text ä¸ºç©ºï¼Œåˆ™è¡¨ç¤ºâ€œåŸºäºå½“å‰å†å²é‡æ–°ç”Ÿæˆâ€ï¼Œæ­¤æ—¶è¦æ±‚å¿…é¡»æœ‰å†å²æ¶ˆæ¯
        const isRegeneratingFromHistory = text.trim() === "" && currentMessages.value.length > 0;

        if (!activeId.value || isGenerating.value) return;
        if (!isRegeneratingFromHistory && !text.trim()) return;

        const startTime = Date.now();
        Logger.stage('Chat Sequence Started');

        const sessionId = activeId.value;
        const currentMode = configStore.settings.chatMode?.enabled ? "Social" : "Standard";

        // Log Context
        Logger.context({
            'Session ID': sessionId,
            'Mode': currentMode,
            'Model': configStore.settings.selectedModelId,
            'Provider': configStore.settings.defaultProviderId,
            'Reasoning': useReasoning.value,
            'Search': useSearch.value,
            'Regenerating': isRegeneratingFromHistory
        });

        isGenerating.value = true;

        // è®¾ç½®æ­£åœ¨ç”Ÿæˆæ¶ˆæ¯çš„ä¼šè¯ ID å¹¶æ¸…ç©ºä¹‹å‰çš„ç¼“å­˜
        generatingSessionId.value = sessionId;
        pausedChunks.value = { content: [], reasoning: [] };
        streamQueue.value = []; // Clear queue at start

        const isStreamEnabled = configStore.settings.chatMode?.enabled
            ? configStore.settings.chatMode.enableStream
            : configStore.settings.enableStream;

        try {
            await invoke("reset_ai_generation");

            if (!isRegeneratingFromHistory) {
                const msgId = await invoke<number>("save_message", {
                    sessionId,
                    role: "user",
                    content: text,
                    reasoningContent: null,
                    fileMetadata: fileMetadata,
                    searchMetadata: null
                });

                // æ·»åŠ åˆ°å½“å‰æ¶ˆæ¯åˆ—è¡¨
                currentMessages.value.push({
                    id: msgId,
                    role: "user",
                    content: text,
                    reasoningContent: null,
                    fileMetadata: fileMetadata,
                    searchMetadata: null
                });
            }

            // æ·»åŠ åŠ è½½ä¸­çš„åŠ©æ‰‹æ¶ˆæ¯
            currentMessages.value.push({
                role: "assistant",
                model: configStore.settings.selectedModelId,
                providerId: configStore.settings.defaultProviderId,
                content: '__LOADING__',
                reasoningContent: '',
                fileMetadata: null,
                searchMetadata: null
            });

            Logger.info('Step: User message saved and UI updated');

            const onEvent = new Channel<string>();
            let aiFullContent = '';
            let ttft = 0; // Time to first token
            let searchStartTime = 0;
            let memoryStartTime = 0;

            // ç›‘å¬æœç´¢çŠ¶æ€äº‹ä»¶
            const unlistenSearch = await listen('search-status', (event: any) => {
                const payload = event.payload;
                const lastMsg = currentMessages.value[currentMessages.value.length - 1];

                if (payload.status === 'searching') {
                    searchStartTime = Date.now();
                    Logger.info(`Searching: ${payload.query}`);
                    lastMsg.searchStatus = 'searching';
                    lastMsg.searchQuery = payload.query;
                } else if (payload.status === 'done') {
                    const searchDuration = Date.now() - searchStartTime;
                    Logger.success('Search completed', searchDuration, { results: payload.results?.length });
                    lastMsg.searchStatus = 'done';
                    lastMsg.searchMetadata = JSON.stringify(payload.results);
                } else if (payload.status === 'error') {
                    Logger.error('Search failed', payload.message);
                    lastMsg.searchStatus = 'error';
                }
            });

            // ç›‘å¬è®°å¿†æ£€ç´¢äº‹ä»¶
            const unlistenMemory = await listen('memory-status', (event: any) => {
                const payload = event.payload;
                if (payload.status === 'searching') {
                    memoryStartTime = Date.now();
                    Logger.info('Retrieving memory context...');
                } else if (payload.status === 'done') {
                    const memoryDuration = Date.now() - memoryStartTime;
                    Logger.success('Memory retrieval completed', memoryDuration, { hasContext: payload.has_context });
                }
            });

            onEvent.onmessage = (data) => {
                if (!isGenerating.value) return;

                if (ttft === 0 && (data.startsWith("c:") || data.startsWith("r:"))) {
                    ttft = Date.now() - startTime;
                    Logger.timing('Time to First Token (TTFT)', ttft);
                }

                // åªè¦æ˜¯å½“å‰ä¼šè¯å°±æ›´æ–°ï¼ˆä¸ç®¡è§†å›¾æ˜¯å¦éšè—ï¼‰
                const isCurrentSession = activeId.value === generatingSessionId.value;
                const lastMsg = currentMessages.value[currentMessages.value.length - 1];

                // å¤„ç†å†…å®¹æµ
                if (data.startsWith("c:")) {
                    const content = data.substring(2);
                    aiFullContent += content;

                    // ğŸŒŠ Streaming Control
                    if (isStreamEnabled) {
                        for (const char of content) {
                            streamQueue.value.push(char);
                        }
                        // Kickstart the processor if idle
                        processStreamQueue();
                    }
                }
                // å¤„ç†æ¨ç†æµ
                else if (data.startsWith("r:")) {
                    const content = data.substring(2);

                    // åŒæ­¥æ›´æ–° tempGeneratedMessage
                    if (tempGeneratedMessage.value) {
                        tempGeneratedMessage.value.reasoning += content;
                    }

                    if (isCurrentSession) {
                        if (!lastMsg.reasoningContent) lastMsg.reasoningContent = "";
                        lastMsg.reasoningContent += content;
                    }
                } else if (data.startsWith("data: ")) {
                    // console.log(`ğŸ§  [DEBUG] Raw data event: ${data.substring(0, 50)}...`);
                } else {
                    // console.log(`ğŸ§  [DEBUG] Unknown event prefix: ${data.substring(0, 10)}`);
                }
            };

            // å‡†å¤‡å‘é€çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆæ’é™¤åŠ è½½ä¸­çš„æ¶ˆæ¯ï¼‰
            let msgsToSend = currentMessages.value.slice(0, -1).map((m) => ({
                role: m.role,
                content: m.content,
                reasoningContent: m.reasoningContent,
                fileMetadata: m.fileMetadata,
                searchMetadata: m.searchMetadata,
                mode: currentMode,
                roleId: "default"
            }));

            // è·å–å½“å‰é¢„è®¾
            const activePreset = configStore.settings.presets.find(p => p.id === configStore.settings.defaultPresetId);

            // æ³¨å…¥ç³»ç»Ÿæç¤ºè¯
            // ç­–ç•¥ï¼šå¦‚æœç¬¬ä¸€æ¡ä¸æ˜¯ç³»ç»Ÿæç¤ºè¯ï¼Œåˆ™æ’å…¥ï¼›å¦‚æœæ˜¯ï¼Œåˆ™æŒ‰éœ€æ›´æ–°å†…å®¹

            let presetPrompt = activePreset?.systemPrompt;

            // ğŸŸ¢ Fix: å¦‚æœä½¿ç”¨çš„æ˜¯â€œé»˜è®¤é¢„è®¾â€ï¼ˆdefault_presetï¼‰ï¼Œåˆ™å¼ºåˆ¶å¿½ç•¥é¢„è®¾å†…éƒ¨å¯èƒ½ä¿å­˜çš„æ—§æç¤ºè¯ï¼Œ
            // ç›´æ¥ä½¿ç”¨ç”¨æˆ·åœ¨å…¨å±€è®¾ç½®ä¸­é…ç½®çš„â€œé»˜è®¤ç³»ç»Ÿæç¤ºè¯â€ã€‚
            // è¿™å“åº”äº†ç”¨æˆ·çš„éœ€æ±‚ï¼šâ€œä¸è¦è®©åˆ«çš„ï¼ˆæ—§é¢„è®¾å€¼ï¼‰å½±å“å®ƒï¼Œç›´æ¥ç”¨è®¾ç½®é‡Œçš„é‚£ä¸ªâ€ã€‚
            if (activePreset?.id === 'default_preset') {
                presetPrompt = "";
            }

            const finalSystemPrompt = presetPrompt || configStore.settings.defaultSystemPrompt || DEFAULT_SYSTEM_PROMPT;

            if (msgsToSend.length > 0 && msgsToSend[0].role !== 'system') {
                msgsToSend.unshift({
                    role: 'system',
                    content: finalSystemPrompt,
                    reasoningContent: null,
                    fileMetadata: null,
                    searchMetadata: null,
                    mode: currentMode,
                    roleId: "default"
                });
            } else if (msgsToSend.length > 0 && msgsToSend[0].role === 'system') {
                msgsToSend[0].content = finalSystemPrompt;
            }

            // æ³¨å…¥ä¼šè¯ç‰¹å®šçš„ç³»ç»Ÿæç¤ºè¯ï¼ˆè¦†ç›–é¢„è®¾æç¤ºè¯ï¼Œå¦‚æœå­˜åœ¨ï¼‰
            const sessionSpecificPrompt = activeSession.value?.system_prompt;
            if (sessionSpecificPrompt) {
                if (msgsToSend.length === 0 || msgsToSend[0].role !== 'system') {
                    console.log('ğŸ§  [DEBUG] Injecting session specific system prompt:', sessionSpecificPrompt);
                    msgsToSend.unshift({
                        role: 'system',
                        content: sessionSpecificPrompt,
                        reasoningContent: null,
                        fileMetadata: null,
                        searchMetadata: null,
                        mode: currentMode,
                        roleId: "default"
                    });
                } else {
                    console.log('ğŸ§  [DEBUG] Updating existing system prompt with session specific:', sessionSpecificPrompt);
                    msgsToSend[0].content = sessionSpecificPrompt;
                }
            }

            console.log("ğŸ“¤ Final messages to send:", {
                count: msgsToSend.length,
                preset: activePreset?.name,
                temperature: activePreset?.temperature,
                maxTokens: activePreset?.maxTokens
            });

            // å¦‚æœå¯ç”¨æ¨ç†ï¼Œåœ¨æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å‰æ·»åŠ æ ‡è®°
            if (useReasoning.value || useSearch.value) {
                for (let i = msgsToSend.length - 1; i >= 0; i--) {
                    if (msgsToSend[i].role === "user") {
                        if (useReasoning.value) msgsToSend[i].content = `[REASON]${msgsToSend[i].content}`;
                        if (useSearch.value) {
                            const tag = provider === 'all' ? '[SEARCH]' : `[SEARCH:${provider}]`;
                            msgsToSend[i].content = `${tag}${msgsToSend[i].content}`;
                        }
                        break;
                    }
                }
            }

            // è°ƒç”¨ AI
            try {
                // ğŸ›¡ï¸ ä¿®å¤ï¼šå¢åŠ  60 ç§’è¶…æ—¶ä¿æŠ¤ï¼Œé˜²æ­¢åç«¯æ— å“åº”å¯¼è‡´ä¸€ç›´è½¬åœˆ
                // Create a timeout promise
                const timeoutPromise = new Promise((_, reject) => {
                    setTimeout(() => reject(new Error("Request timed out")), 60000);
                });

                await Promise.race([
                    invoke("ask_ai", {
                        msg: msgsToSend,
                        onEvent,
                        temperature: activePreset?.temperature,
                        max_tokens: activePreset?.maxTokens,
                        // ğŸŸ¢ Fix: Explicitly pass the resolved provider and model to the backend
                        // This prevents the backend from falling back to the potentially stale global config
                        explicitProviderId: configStore.settings.defaultProviderId,
                        explicitModelId: configStore.settings.selectedModelId,
                        stream: isStreamEnabled
                    }),
                    timeoutPromise
                ]);

                // ğŸ›‘ Non-Streaming Mode: Final Update
                // If streaming is disabled, we need to manually update the UI with the full content once generation completes.
                if (!isStreamEnabled) {
                    const lastMsg = currentMessages.value[currentMessages.value.length - 1];
                    if (lastMsg && lastMsg.role === 'assistant') {
                        // Replace __LOADING__ with actual content
                        if (lastMsg.content === "__LOADING__") lastMsg.content = "";
                        lastMsg.content = aiFullContent;
                    }
                }
            } finally {
                unlistenSearch();
                unlistenMemory();
            }

            const totalDuration = Date.now() - startTime;
            Logger.success('AI generation completed', totalDuration);

            // è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„æ·±åº¦æ€è€ƒå†…å®¹
            const lastMsg = currentMessages.value[currentMessages.value.length - 1];

            const finalReasoningContent = lastMsg.reasoningContent || null;
            const finalSearchMetadata = lastMsg.searchMetadata || null;

            // ä¿å­˜åŠ©æ‰‹å›å¤ - åªåœ¨ç”Ÿæˆå®Œæˆåä¿å­˜å®Œæ•´çš„ AI å›å¤
            await saveAssistantResponse(sessionId, aiFullContent, finalReasoningContent, null, finalSearchMetadata);

            // è‡ªåŠ¨æ€»ç»“æ ‡é¢˜
            const msgCount = currentMessages.value.filter(m => m.content && m.content !== "__LOADING__").length;
            const isDefaultTitle = !activeSession.value?.title ||
                ["æ–°å¯¹è¯", "é»˜è®¤ä¼šè¯", "New Chat", "é»˜è®¤å¯¹è¯"].includes(activeSession.value?.title);

            // å½“æ¶ˆæ¯æ•°è¾¾åˆ° 2 æ¡ï¼ˆä¸€ä¸ªå›åˆï¼‰ä¸”æ ‡é¢˜è¿˜æ˜¯é»˜è®¤å€¼æ—¶ï¼Œè§¦å‘è‡ªåŠ¨æ€»ç»“
            if (msgCount >= 2 && isDefaultTitle) {
                autoSummaryTitle(sessionId);
            }
            console.log("ğŸ’¾ [SAVE] === END SAVING ===");
        } catch (error: any) {
            console.error("å¯¹è¯å¤±è´¥:", error);

            // ğŸš¨ Error Handling UI
            const lastMsg = currentMessages.value[currentMessages.value.length - 1];
            if (lastMsg.role === 'assistant' && lastMsg.content === '__LOADING__') {
                // Determine error type based on message
                let errorType = 'unknown';
                let errorMsg = error.message || String(error);
                let details = '';

                if (errorMsg.includes('timed out')) {
                    errorType = 'timeout';
                    errorMsg = 'è¯·æ±‚è¶…æ—¶ (60s)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•ã€‚';
                } else if (errorMsg.includes('quota') || errorMsg.includes('429')) {
                    errorType = 'quota';
                    errorMsg = 'è¯·æ±‚é€Ÿç‡è¶…è¿‡é™åˆ¶æˆ–é…é¢ä¸è¶³ã€‚';
                    details = 'https://ai.google.dev/gemini-api/docs/rate-limits';
                }

                // Replace loading message with error state
                lastMsg.content = '';
                lastMsg.error = {
                    message: errorMsg,
                    type: errorType,
                    details: details,
                    originalError: String(error)
                };
            }

        } finally {
            isGenerating.value = false;
            // æ¸…ç©ºç”Ÿæˆä¼šè¯çŠ¶æ€å’Œç¼“å­˜
            // generatingSessionId.value = null; // DO NOT clear here. It breaks the "isCurrentSession" check in the queue loop for the last few chars.
            pausedChunks.value = { content: [], reasoning: [] };
            // streamQueue.value = []; // DO NOT clear queue here, let it drain naturally
        }
    };

    const stopGeneration = async () => {
        isGenerating.value = false;
        // æ¸…ç©ºç”Ÿæˆä¼šè¯çŠ¶æ€å’Œç¼“å­˜
        generatingSessionId.value = null;
        pausedChunks.value = { content: [], reasoning: [] };
        streamQueue.value = []; // Clear queue on stop
        try { await invoke("stop_ai_generation"); } catch (err) { console.error(err); }
    };

    const clearMessages = async (sessionId: string) => {
        try {
            // 1. è°ƒç”¨ Rust åç«¯æ¸…ç©ºæ¶ˆæ¯
            await invoke("clear_messages", { sessionId });

            // 2. å¦‚æœæ˜¯å½“å‰ä¼šè¯ï¼Œæ¸…ç©ºæœ¬åœ°æ˜¾ç¤º
            if (activeId.value === sessionId) {
                currentMessages.value = [{ role: "system", content: "ä½ æ˜¯ä¸€ä¸ªç®€æ´ä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚" }];
            }
        } catch (e) {
            console.error("æ¸…ç©ºæ¶ˆæ¯å¤±è´¥:", e);
        }
    };

    const deleteMessageAction = async (messageId: number | undefined, index: number) => {
        try {
            if (messageId) {
                await invoke("delete_message", { messageId });
            }
            currentMessages.value.splice(index, 1);
        } catch (e) {
            console.error("åˆ é™¤æ¶ˆæ¯å¤±è´¥:", e);
        }
    };

    const editMessageAction = async (messageId: number | undefined, index: number, newContent: string) => {
        try {
            if (!activeId.value) return;

            // 1. æ›´æ–°æ•°æ®åº“ä¸­è¯¥æ¡æ¶ˆæ¯çš„å†…å®¹
            if (messageId) {
                await invoke("update_message", { messageId, content: newContent });

                // 2. åˆ é™¤è¯¥æ¡æ¶ˆæ¯ä¹‹åçš„æ‰€æœ‰æ¶ˆæ¯
                await invoke("delete_messages_after", {
                    sessionId: activeId.value,
                    messageId: messageId
                });
            }

            // 3. æ›´æ–°æœ¬åœ°çŠ¶æ€ï¼šä¿®æ”¹å†…å®¹å¹¶æˆªæ–­åˆ—è¡¨
            currentMessages.value[index].content = newContent;
            currentMessages.value = currentMessages.value.slice(0, index + 1);

            // 4. é‡æ–°è§¦å‘ AI å›ç­”
            await sendMessage(""); // ä¼ ç©ºå­—ç¬¦ä¸²è§¦å‘é€»è¾‘
        } catch (e) {
            console.error("ç¼–è¾‘æ¶ˆæ¯å¤±è´¥:", e);
        }
    };

    const regenerateAction = async (index: number) => {
        try {
            if (!activeId.value) return;

            // 1. å¦‚æœå½“å‰ç‚¹å‡»çš„æ˜¯ assistant æ¶ˆæ¯ï¼Œå…ˆåˆ é™¤å®ƒ
            const msg = currentMessages.value[index];
            if (msg.role === 'assistant' && msg.id) {
                await invoke("delete_message", { messageId: msg.id });
                currentMessages.value.splice(index, 1);
            }

            // 2. é‡æ–°è§¦å‘ AI å›ç­” (åŸºäºæœ€åä¸€æ¡ user æ¶ˆæ¯)
            await sendMessage("");
        } catch (e) {
            console.error("é‡æ–°ç”Ÿæˆå¤±è´¥:", e);
        }
    };
    // ğŸ•µï¸ å®æ—¶åŒæ­¥ç›‘å¬ï¼šå½“ç”¨æˆ·åœ¨ UI ä¿®æ”¹æ¨¡å‹/é¢„è®¾æ—¶ï¼Œå¦‚æœå½“å‰æœ‰æ´»è·ƒä¼šè¯ï¼Œç«‹å³æŒä¹…åŒ–
    watch(
        [() => configStore.settings.selectedModelId, () => configStore.settings.defaultPresetId],
        async ([newModel, newPreset]) => {
            if (isInternalSync || !activeId.value) return;

            console.log("ğŸ› ï¸ æ£€æµ‹åˆ° UI é…ç½®å˜æ›´ï¼Œæ­£åœ¨åŒæ­¥è‡³ä¼šè¯:", activeId.value);
            try {
                await invoke("update_session_config", {
                    id: activeId.value,
                    presetId: newPreset,
                    modelId: newModel,
                    systemPrompt: activeSession.value?.system_prompt || null
                });

                // åŒæ­¥æœ¬åœ°å†…å­˜çŠ¶æ€
                if (activeSession.value) {
                    activeSession.value.preset_id = newPreset;
                    activeSession.value.model_id = newModel;
                }
            } catch (e) {
                console.error("åŒæ­¥ä¼šè¯é…ç½®å¤±è´¥:", e);
            }
        }
    );

    return {
        processStreamQueue,
        applyPausedChunks,
        setChatViewActive,
        loadMessages,
        sendMessage,
        stopGeneration,
        clearMessages,
        deleteMessageAction,
        editMessageAction,
        regenerateAction,
        saveAssistantResponse,
        autoSummaryTitle
    };
}
