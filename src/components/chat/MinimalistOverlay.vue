<script setup>
import { ref, computed, onMounted, onUnmounted, watch, nextTick } from 'vue';
import { invoke, convertFileSrc, Channel } from '@tauri-apps/api/core';
import { resolveResource } from '@tauri-apps/api/path';
import { listen, emit as tauriEmit } from '@tauri-apps/api/event';
import { useChatStore } from '../../stores/chat';
import { useConfigStore } from '../../stores/config';
import * as PIXI from 'pixi.js';
import ModelDownloadProgress from '../common/ModelDownloadProgress.vue';
import { Live2DModel, config } from 'pixi-live2d-display';
import { ask } from '@tauri-apps/plugin-dialog';

// ğŸ¨ å¼•å…¥æç®€æ¨¡å¼ä¸“å±æ ·å¼è¡¨ (ä½ å¯ä»¥ä¿®æ”¹ assets/css/minimalist.css)
import '../../assets/css/minimalist.css';
// ğŸŸ¢ ã€å”¯ä¸€æ§åˆ¶æŒ‰é’®ã€‘ - æ”¹è¿™ä¸ªæ•°ï¼ŒAlice å°±ä¼šå˜å¤§å˜å°
// ========================================================
const SIZE = 1.25;
const ALICE_ZOOM = 1;  
const Y_OFFSET = 0.5;
// ========================================================

// æ ¸å¿ƒé…ç½® (æ ¹æ® Alice æ¨¡å‹çš„ 77 ä¸ªé®ç½©è¿›è¡Œä¿®æ­£)
// å…¨å±€æ³¨å…¥ PIXI (åœ¨ä»»ä½• Live2D æ“ä½œä¹‹å‰)
if (typeof window !== 'undefined') {
  window.PIXI = PIXI;
}

// æ ¸å¿ƒé…ç½® (æ ¹æ® Alice æ¨¡å‹çš„ 77 ä¸ªé®ç½©è¿›è¡Œä¿®æ­£)
config.cubism4.maskSize = 4096;
config.cubism4.renderTextureCount = 1; // ğŸ­ å¿…é¡»ä¸º 1ï¼Œé…åˆé­”æ”¹åº“ä½¿ç”¨
if (Live2DModel.config) {
    Live2DModel.config.maxMasks = 256; // ğŸ­ è¿›ä¸€æ­¥æé«˜ä¸Šé™ try 256
}

// æ€§èƒ½æ¨¡å¼å®Œå…¨åŒæ­¥
PIXI.Program.defaultFragmentPrecision = PIXI.PRECISION.MEDIUM;
PIXI.Ticker.shared.maxFPS = 240;
PIXI.Filter.defaultResolution = window.devicePixelRatio || 1;

const props = defineProps({
  visible: { type: Boolean, default: false }
});

const emit = defineEmits(['close', 'send']);

const chatStore = useChatStore();
const configStore = useConfigStore();
const inputText = ref('');
const inputRef = ref(null);
const isSending = ref(false);
const isRecording = ref(false);

const mediaRecorder = ref(null);

// âœ¨ ASR æ¨¡å‹ä¸‹è½½çŠ¶æ€
const isDownloadingModel = ref(false);
const downloadProgress = ref(0);
const downloadStatusText = ref('æ­£åœ¨å‡†å¤‡ä¸‹è½½ AI æ¨¡å‹...');
const downloadDetail = ref(''); // e.g. "15.2 MB / 200.5 MB"
const audioChunks = ref([]);

// å­—å¹•ç›¸å…³çŠ¶æ€
const subtitleText = ref('');
const isTyping = ref(false);

// æ‹–æ‹½çª—å£ä½ç½®çŠ¶æ€
const windowPos = ref({ x: 0, y: 0 });
const isDragging = ref(false);
const dragOffset = ref({ x: 0, y: 0 });
const inputWidth = ref(1200);

// Live2D ç›¸å…³çŠ¶æ€
const live2dApp = ref(null);
const live2dModel = ref(null);
const isSpeaking = ref(false);
const currentLipValue = ref(0);
// ğŸš€ [æ ¸å¿ƒä¿®å¤]ï¼šæ¨¡å‹ä½ç½®ç‹¬ç«‹åŒ–ï¼Œä¸å†ç»‘å®šçª—å£
const modelPos = ref({ x: 0, y: 0 });
const isModelDragging = ref(false);

// ğŸ¤ TTS æµå¼æ’­æ”¾ç›¸å…³çŠ¶æ€
const audioQueue = ref([]);
const isPlayingAudio = ref(false);
const currentAudioElement = ref(null);
const accumulatedText = ref(''); // ç´¯ç§¯çš„æ–‡æœ¬,ç”¨äºå¥å­åˆ‡åˆ†

// ğŸš€ [V3] åºåˆ—åŒ–æ’­æ”¾æ§åˆ¶
const nextAssignIndex = ref(0); // ğŸš€ [é‡æ„] ä¸‹ä¸€ä¸ªè¦åˆ†é…ç»™æ–‡æ®µçš„åºå·
const nextToDeliverIndex = ref(0); // ğŸš€ [é‡æ„] æœŸæœ›å…¥é˜Ÿçš„éŸ³é¢‘åºå·
const pendingAudioMap = ref(new Map()); // å­˜å‚¨ä¹±åºåˆ°è¾¾çš„éŸ³é¢‘ {sequenceIndex: audioItem}
const sentenceBuffer = ref(''); // ğŸš€ [V3] çŸ­å¥åˆå¹¶ç¼“å†²åŒº
const MIN_SENTENCE_LENGTH = 18; // ğŸš€ [æµæ°´çº¿] ç›®æ ‡èŒƒå›´ä¸‹é™ (18-25)
const MIN_FIRST_SENTENCE_LENGTH = 6; // ğŸš€ [æµæ°´çº¿] é¦–å¥ç›®æ ‡ä¸‹é™ (6-10)
const INACTIVITY_TIMEOUT = 300; // ğŸš€ [æµæ°´çº¿] 300ms åœé¡¿å¼ºåˆ¶è§¦å‘
const inactivityTimer = ref(null);

// ğŸš€ [æ™ºèƒ½åˆ†è¯] åˆå§‹åŒ–æµè§ˆå™¨åŸç”Ÿåˆ†è¯å™¨
const segmenter = new Intl.Segmenter('zh', { granularity: 'word' });

// ğŸš€ [V6] å¹¶å‘æ§åˆ¶é˜Ÿåˆ—
const MAX_CONCURRENT_TTS = 1; // ğŸš€ [ä¼˜åŒ–] ä¸²è¡Œå¤„ç† (Concurrency=1) ä»¥å‡å°‘æ˜¾å­˜ç«äº‰å’Œåˆ‡æ¢å¼€é”€
const ttsRequestQueue = ref([]);
const activeTTSRequests = ref(0);


const processTTSQueue = async () => {
    if (activeTTSRequests.value >= MAX_CONCURRENT_TTS || ttsRequestQueue.value.length === 0) {
        return;
    }

    const { sentence, taskId, sequenceIndex, audioItem, resolve, reject } = ttsRequestQueue.value.shift();
    activeTTSRequests.value++;

    try {
        console.log(`[TTS] [å¼€å§‹] å¤„ç†è¯·æ±‚ (åºå·: ${sequenceIndex}), å½“å‰å¹¶å‘: ${activeTTSRequests.value}`);
        
        // ğŸš€ [ä¼˜åŒ–] å®šä¹‰äºŒè¿›åˆ¶å›è°ƒ Channel
        const onEventChannel = new Channel();
        onEventChannel.onmessage = (event) => {
            const { type, data } = event;
            
            // ğŸš€ [æ€§èƒ½ç›‘æµ‹] è®°å½• TTS é¦–å£°è€—æ—¶
            if (type === 'metadata' && Number(sequenceIndex) === 0) {
                 const { backend_prep_ms } = data;
                 perfMetrics.value.ttsFirstAudioTime = performance.now();
                 const totalLatency = perfMetrics.value.ttsFirstAudioTime - perfMetrics.value.sendTime;
                 console.log(`[æ€§èƒ½] å»¶è¿Ÿç»Ÿè®¡ (æ€»è®¡: ${totalLatency.toFixed(0)}ms)`);
                 console.log(`  - åç«¯æ¨ç†: ${backend_prep_ms}ms`);
                 perfMetrics.value.hasTrackedTTS = true;
            }

            if (type === 'chunk') {
                let raw = new Uint8Array(data).buffer;
                
                // ğŸš€ [WAV å‰¥ç¦»] é€»è¾‘ä¸‹ç§»è‡³æ­¤
                if (audioItem.chunks.length === 0 && raw.byteLength >= 44) {
                    const u8 = new Uint8Array(raw);
                    if (u8[0] === 0x52 && u8[1] === 0x49 && u8[2] === 0x46 && u8[3] === 0x46) {
                        // ğŸ§ [åŠ¨æ€é‡‡æ ·ç‡æ¢æµ‹] ä» WAV å¤´åç§» 24 å­—èŠ‚å¤„è¯»å–é‡‡æ ·ç‡ (Little-endian 4-byte)
                        const sr = u8[24] | (u8[25] << 8) | (u8[26] << 16) | (u8[27] << 24);
                        if (sr > 8000 && sr < 192000) {
                            console.log(`[TTS] [æ¢æµ‹] å‘ç° WAV å¤´, é‡‡æ ·ç‡: ${sr}Hz`);
                            audioItem.sampleRate = sr;
                        } else {
                            console.log('[TTS] [è­¦å‘Š] WAV å¤´é‡‡æ ·ç‡å¼‚å¸¸, ç»´æŒé»˜è®¤');
                        }
                        raw = raw.slice(44);
                    }
                }

                const isMatch = isPlayingAudio.value && Number(currentStreamingSequence.value) === Number(sequenceIndex);
                if (isMatch) {
                    schedulePCMChunk(raw, audioItem.sampleRate || 32000);
                } else {
                    audioItem.chunks.push(raw);
                }
            }

            if (type === 'done') {
                audioItem.isDone = true;
                // console.log(`[TTS] [DONE] Sequence ${sequenceIndex} Binary stream complete`);
            }
        };

        const result = await invoke('generate_tts', {
            text: sentence,
            textLanguage: audioItem.language || 'zh',
            requestId: taskId,
            sequenceId: sequenceIndex,
            onEvent: onEventChannel
        });
        // ğŸš€ [å…³é”®ä¿®å¤] Invoke è¿”å›æ„å‘³ç€æµå·²ç»ç»“æŸã€‚å³ä½¿æ²¡æ”¶åˆ° Chunk (æ¯”å¦‚åªæœ‰æ ‡ç‚¹)ï¼Œä¹Ÿè¦æ ‡ä¸º Doneã€‚
        audioItem.isDone = true;
        console.log(`[TTS] [å®Œæˆ] è¯·æ±‚å¤„ç†å®Œæ¯• (åºå·: ${sequenceIndex})`);
        resolve(result);
    } catch (e) {
        console.error(`[TTS] [é”™è¯¯] è¯·æ±‚å¤„ç†å¤±è´¥ (åºå·: ${sequenceIndex}):`, e);
        reject(e);
    } finally {
        activeTTSRequests.value--;
        processTTSQueue(); // é€’å½’å¤„ç†ä¸‹ä¸€ä¸ª
    }
};

// ğŸš€ [V2] ä»»åŠ¡é”å®šä¸è¯·æ±‚ ID
const currentRequestId = ref(0);
const currentSessionToken = ref(''); 
const isWaitingForResponse = ref(false); // ğŸš€ [V2] ç”¨äºè¿‡æ»¤æ—§æ¶ˆæ¯çš„æµ

// ğŸš€ [V5] å­—èŠ‚æµæ’­æ”¾æ ¸å¿ƒçŠ¶æ€
const audioCtx = ref(null);
const nextChunkTime = ref(0);
const residualBuffer = ref(null); // ğŸš€ [ä¿®å¤] ç”¨äºå¤„ç† PCM å­—èŠ‚å¯¹é½çš„æ®‹ç•™ç¼“å†²åŒº
const currentStreamingSequence = ref(-1);
const isStreamPlaying = ref(false);

// ğŸš€ [æ€§èƒ½ç›‘æµ‹] æµ‹é‡æ‰“ç«å»¶è¿Ÿ
const perfMetrics = ref({
    sendTime: 0,
    llmFirstTokenTime: 0,
    ttsTriggerStartTime: 0, // LLM å‡ºç¬¬ä¸€ä¸ªè¯çš„æ—¶é—´
    ttsRequestStartTime: 0, // çœŸæ­£å‘ç»™ Rust åç«¯çš„æ—¶é—´
    ttsFirstAudioTime: 0,
    hasTrackedLLM: false,
    hasTrackedTTS: false
});

const initAudioContext = async () => {
    if (!audioCtx.value) {
        // AudioContext çš„é‡‡æ ·ç‡è®¾ä¸º 48k ä½œä¸ºåŸºç¡€å®¹å™¨å³å¯ï¼Œå…·ä½“æ’­æ”¾ä¼šé€šè¿‡ createBuffer è‡ªåŠ¨é‡é‡‡æ ·
        audioCtx.value = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 48000 });
        console.log('[éŸ³é¢‘] ä¸Šä¸‹æ–‡å·²åˆå§‹åŒ– (48000Hz åŸºç¡€å®¹å™¨), çŠ¶æ€:', audioCtx.value.state);
    }
    if (audioCtx.value.state === 'suspended') {
        return audioCtx.value.resume().then(() => {
            console.log('[éŸ³é¢‘] ä¸Šä¸‹æ–‡å·²æ¢å¤');
        });
    }
    return Promise.resolve();
};

// å¤åˆ»ç‹¬ç«‹ç‰ˆçª—å£æ‹–æ‹½
const onWindowMouseDown = (e) => {
  if (e.button === 0) {
    startDragging(e);
  }
};

const initPosition = () => {
    const width = window.innerWidth;
    const height = window.innerHeight;

    // 1. è¾“å…¥æ¡†ä½ç½®ï¼šå±…ä¸­åº•éƒ¨
    const maxWidth = Math.min(1600, width * 0.80);
    inputWidth.value = maxWidth;
    windowPos.value = {
        x: (width - maxWidth) / 2,
        y: height - 50 - 100
    };

    // 2. æ¨¡å‹åˆå§‹ä½ç½®ï¼šå±…ä¸­ (æˆ–ä½ å–œæ¬¢çš„ä»»ä½•ä½ç½®)
    modelPos.value = {
        x: width * 0.5,
        y: height * 0.5
    };
};

const updatePassthroughMonitor = async () => {
    if (!props.visible) return;
    try {
        const regions = [];
        // ğŸš€ [æ€§èƒ½æ ¸å¿ƒ] æ‹–æ‹½ä¸­åˆ¤å®šåŒºé”å®šä¸ºå…¨å±ï¼Œä¸”ä¸éšä½ç½®æ›´æ–°è§¦å‘ IPC
        if (isDragging.value || isModelDragging.value) {
            regions.push({ x: 0, y: 0, w: window.innerWidth, h: window.innerHeight });
        } else {
            // 1. è¾“å…¥æ¡†åˆ¤å®šåŒº
            regions.push({ x: windowPos.value.x, y: windowPos.value.y, w: inputWidth.value, h: 100 });
            // 2. æ¨¡å‹åˆ¤å®šåŒº
            if (live2dModel.value) {
                const model = live2dModel.value;
                regions.push({
                    x: model.x - (model.width * 0.4),
                    y: model.y - (model.height * 0.5),
                    w: model.width * 0.8,
                    h: model.height * 0.9
                });
            }
        }

        const regionsStr = JSON.stringify(regions);
        if (window._lastPassthroughRegions === regionsStr) return;
        window._lastPassthroughRegions = regionsStr;

        await invoke('start_passthrough_monitor', { regions });
    } catch (e) {
        console.error('Failed to update passthrough regions:', e);
    }
};

// æ¢æµ‹æ˜¯å¦æ­£åœ¨æ‹–æ‹½
const isAnyDragging = computed(() => isDragging.value || isModelDragging.value);

// ğŸš€ [æ€§èƒ½æ ¸å¿ƒ] ä»…ç›‘å¬çŠ¶æ€åˆ‡æ¢ï¼Œä¸ç›‘å¬å…·ä½“åæ ‡
watch([isAnyDragging, () => props.visible, live2dModel], () => {
    updatePassthroughMonitor();
}, { immediate: true });

// ç›‘å¬å…¨å±€é¼ æ ‡åæ ‡ (ä»…ç”¨äºçœ‹å‘é¼ æ ‡)
let unlistenMouseMove = null;
onMounted(async () => {
    unlistenMouseMove = await listen('global-mouse-move', (event) => {
        window.mouseX = event.payload.x;
        window.mouseY = event.payload.y;
    });
});

// ç§»åˆ°é¡¶å±‚åŒæ­¥æ³¨å†Œ
onUnmounted(() => {
    if (unlistenMouseMove) unlistenMouseMove();
});

// ç›‘å¬å¯è§æ€§
watch(() => props.visible, (newVal) => {
  if (newVal) {
    if (windowPos.value.y === 0) initPosition();
    setTimeout(() => {
        inputRef.value?.focus();
        updatePassthroughMonitor();
        initLive2D();
    }, 400);
  } else {
    invoke('set_window_ignore_cursor_events', { ignore: false });
    
    // ğŸ¤ å…³é—­ç®€çº¦æ¨¡å¼æ—¶åœæ­¢ TTS
    stopAllTTS();
    
    if (live2dApp.value) {
        console.log('[ç³»ç»Ÿ] é”€æ¯ Live2D App');
        live2dApp.value.destroy(false, { children: true, texture: true, baseTexture: true });
        live2dApp.value = null;
        live2dModel.value = null;
    }
  }
});

// ğŸš€ [ä¿®å¤] ç§»é™¤å¯¹ live2dModel çš„ deep watchï¼Œé˜²æ­¢ Vue æ·±åº¦éå†å¤æ‚ Pixi å¯¹è±¡å¯¼è‡´é€’å½’æº¢å‡º
watch([windowPos, isDragging, isModelDragging, live2dModel], () => {
    if (props.visible) updatePassthroughMonitor();
});

// Live2D åˆå§‹åŒ–
const initLive2D = async () => {
  try {
    const canvas = document.getElementById('live2d-canvas');
    if (!canvas) return;

    const app = new PIXI.Application({
      view: canvas,
      autoStart: true,
      backgroundAlpha: 0,
      resizeTo: window,
      antialias: true,
      premultipliedAlpha: true,
      powerPreference: 'default',
      resolution: window.devicePixelRatio || 1,
      autoDensity: true,
      hello: false
    });
    live2dApp.value = app;
    app.ticker.maxFPS = 240;
    PIXI.Ticker.shared.maxFPS = 240;

    // ğŸš€ [æ‰‹æœ¯çº§ä¿®å¤] ä»èµ„æºè·¯å¾„åŠ è½½æ¨¡å‹ï¼Œå¹¶æ‰‹åŠ¨çº æ­£ URL ç¼–ç ä»¥æ”¯æŒç›¸å¯¹è·¯å¾„è§£æ
    const resourcePath = await resolveResource('resources/live2d/alice/alice_model3.json');
    // convertFileSrc ä¼šç¼–ç æ–œæ ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæ‰‹åŠ¨è§£ç æ–œæ å’Œå†’å·ï¼Œ
    // ä»¥ä¾¿ global-shim é‡Œçš„ new URL() èƒ½è¯†åˆ«ç›®å½•å±‚çº§ï¼Œä½†åˆä¸ç ´å Tauri çš„ asset åè®®ã€‚
    const modelUrl = convertFileSrc(resourcePath)
        .replace(/%2F/g, '/')
        .replace(/%5C/g, '/')
        .replace(/%3A/g, ':');
    
    console.log('[ç³»ç»Ÿ] åŠ è½½ Live2D æ¨¡å‹ (Surgical)...', modelUrl);
    const model = await Live2DModel.from(modelUrl, {
      autoHitTest: true,
      autoFocus: true,
      idleMotionGroup: 'Idle'
    });

    if (!model) {
        console.error('[ç³»ç»Ÿ] [é”™è¯¯] æ¨¡å‹åŠ è½½å¤±è´¥!');
        throw new Error('æ¨¡å‹è§£æå¤±è´¥');
    }
    console.log('[ç³»ç»Ÿ] æ¨¡å‹åŠ è½½æˆåŠŸ');

    live2dModel.value = model;
    app.stage.addChild(model);
    model.anchor.set(0.5, 0.5);
    model.eventMode = 'static';
    
    // ğŸš€ [å…³é”®ä¿®å¤] åˆå§‹ä½ç½®åŒæ­¥
    model.x = modelPos.value.x;
    model.y = modelPos.value.y;

    // ğŸ† [æ¨¡å‹ç‹¬ç«‹æ‹–æ‹½ç›‘å¬]
    const onModelMouseDown = (e) => {
        if (e.button !== 0) {
            if (e.button === 2) isSpeaking.value = !isSpeaking.value;
            return;
        }
        
        isModelDragging.value = true;
        dragOffset.value = {
            x: e.clientX - model.x,
            y: e.clientY - model.y
        };
        
        // ğŸš€ ä½¿ç”¨åŸç”Ÿ mousemove + requestAnimationFrame ç¡®ä¿ä¸æ»‘è·Ÿæ‰‹
        let rafId = null;
        const onMove = (me) => {
            if (rafId) return;
            rafId = requestAnimationFrame(() => {
                const nx = me.clientX - dragOffset.value.x;
                const ny = me.clientY - dragOffset.value.y;
                modelPos.value = { x: nx, y: ny };
                model.x = nx;
                model.y = ny;
                rafId = null;
            });
        };
        
        const onUp = () => {
            isModelDragging.value = false;
            document.removeEventListener('mousemove', onMove);
            window.removeEventListener('mouseup', onUp);
            if (rafId) cancelAnimationFrame(rafId);
        };
        
        document.addEventListener('mousemove', onMove);
        window.addEventListener('mouseup', onUp);
    };
    canvas.addEventListener('mousedown', onModelMouseDown);

    model.internalModel.on('beforeModelUpdate', () => {
      const coreModel = model.internalModel.coreModel;
      if (coreModel) {
        const now = Date.now() / 1000;
        const set = (id, value) => coreModel.setParameterValueById(id, value, 1.0);

        set('Param66', 1.0); set('Param61', 0.0); set('Param62', 1.0);
        const stickX = Math.sin(now * 3) * 0.2;
        const stickY = Math.sin(now * 4) * 0.2;
        set('LeftStickX', stickX); set('RightStickX', -stickX);
        set('LeftStickY', stickY); set('RightStickY', stickY);
        set('ParamBreath', Math.sin(now * 1.5) * 0.5 + 0.5);

        const light = Math.sin(now * 0.8) * 0.5 + 0.5;
        set('light', light); set('Param65', light);

        if (isSpeaking.value) {
          const speed = 8;
          const noise = Math.sin(now * speed) * Math.sin(now * speed * 0.5);
          let targetOpenness = (noise + 1) / 2 * 0.8 + 0.2;
          if (Math.random() > 0.95) targetOpenness = 0;
          currentLipValue.value += (targetOpenness - currentLipValue.value) * 0.1;
        } else {
          currentLipValue.value += (0 - currentLipValue.value) * 0.1;
        }
        set('ParamMouthOpenY', currentLipValue.value);

        if (window.mouseX !== undefined && !isModelDragging.value) {
             model.focus(window.mouseX, window.mouseY);
        }
      }
    });

    const updateLayout = () => {
      app.renderer.resize(window.innerWidth, window.innerHeight);
      
      // ä½¿ç”¨ç‹¬ç«‹çš„æ¨¡å‹ä½ç½®åæ ‡
      model.x = modelPos.value.x;
      model.y = modelPos.value.y;

      const coreModel = model.internalModel.coreModel;
      let s = 1.0;
      if (coreModel && coreModel.canvasHeight) {
        s = (window.innerHeight / coreModel.canvasHeight) * ALICE_ZOOM;
      } else {
        model.scale.set(1);
        s = (window.innerHeight / model.height) * ALICE_ZOOM;
      }
      model.scale.set(s);
    };

    updateLayout();
    // ğŸš€ [å…³é”®ä¿®å¤] åŠ è½½å®Œæˆåç«‹å³åˆ·æ–°ä¸€æ¬¡ç‚¹å‡»åˆ¤å®šåŒº
    updatePassthroughMonitor();
    
    app.renderer.on('destroy', () => {
        canvas.removeEventListener('mousedown', onModelMouseDown);
    });

  } catch (e) {
    console.error('æ¸²æŸ“å¼‚å¸¸:', e);
  }
};

// ç›‘å¬å™¨å¼•ç”¨(ç”¨äºæ¸…ç†)
let unlistenMessage = null;
let unlistenTyping = null;
let unlistenStreaming = null;
let unlistenAudioChunk = null;

onMounted(async () => {
  initPosition(); 
  // ç§»é™¤çª—å£è‡ªåŠ¨é‡ç½®ï¼Œä¿ç•™ç”¨æˆ·æœ€åçš„ä½ç½®
  // window.addEventListener('resize', initPosition);
  
  // ä»…ç›‘å¬ AI çš„æ¶ˆæ¯æ¥æ›´æ–°å­—å¹•æ˜¾ç¤º
  unlistenMessage = await listen('new-social-message', (event) => {
    if (props.visible && event.payload.role === 'assistant') {
      subtitleText.value = event.payload.content;
    }
  });

  unlistenTyping = await listen('typing-status', (event) => {
    if (props.visible) {
      isTyping.value = event.payload.isTyping;
      // åªæœ‰åœ¨æ²¡æœ‰æµå¼å†…å®¹æ—¶ï¼Œæ‰æ˜¾ç¤ºâ€œæ­£åœ¨è¾“å…¥â€
      if (isTyping.value && !subtitleText.value) subtitleText.value = 'æ­£åœ¨è¾“å…¥...';
      if (!isTyping.value && subtitleText.value === 'æ­£åœ¨è¾“å…¥...') subtitleText.value = '';
    }
  });

  // ğŸš€ [æµå¼ä¼ è¾“ç›‘å¬ + TTS ç”Ÿæˆ]
  unlistenStreaming = await listen('social-streaming-chunk', (event) => {
    if (props.visible) {
      // ğŸš€ [V2 æ ¸å¿ƒä¿®å¤] å¦‚æœæˆ‘ä»¬åˆšåˆšå‘é€äº†æ¶ˆæ¯ï¼Œä½†åœ¨ç­‰ç¬¬ä¸€ä¸ª chunk æ—¶æ”¶åˆ°äº†æ—§ chunkï¼Œåˆ™ä¸¢å¼ƒ
      if (isWaitingForResponse.value && !event.payload.isFirst) {
        console.log('[TTS] [è·³è¿‡] ä¸¢å¼ƒè¿‡æ—¶åˆ†å—');
        return;
      }

      if (event.payload.isFirst) {
        // ğŸš€ [æ€§èƒ½ç›‘æµ‹] è®°å½• LLM é¦–å­—è€—æ—¶
        if (!perfMetrics.value.hasTrackedLLM) {
            perfMetrics.value.llmFirstTokenTime = performance.now();
            const latency = perfMetrics.value.llmFirstTokenTime - perfMetrics.value.sendTime;
            console.log(`[æ€§èƒ½] LLM é¦–å­—å»¶è¿Ÿ: ${latency.toFixed(2)}ms`);
            perfMetrics.value.hasTrackedLLM = true;
        }
        isWaitingForResponse.value = false; // æ”¶åˆ°ç¬¬ä¸€ä¸ª chunkï¼Œæ­£å¼å¼€å§‹
        subtitleText.value = event.payload.content;
        accumulatedText.value = event.payload.content;
      } else {
        subtitleText.value += event.payload.content;
        accumulatedText.value += event.payload.content;
      }
      
      isStreamingDone.value = !!event.payload.isDone;

      // ğŸš€ [V3] å¦‚æœæµå¼ä¼ è¾“ç»“æŸ,å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
      if (event.payload.isDone) {
        console.log('[TTS] æµä¼ è¾“ç»“æŸ, åˆ·æ–°ç¼“å†²åŒº');
        flushSentenceBuffer();
      } else {
        // ğŸ¤ æ£€æµ‹å¥å­ç»“æŸ,å°è¯•åˆå¹¶æˆ–è§¦å‘ TTS ç”Ÿæˆ
        checkAndGenerateTTS();
      }
    }
  });

  // ğŸš€ [V5] æ¥æ”¶éŸ³é¢‘åˆ†ç‰‡ (å·²åºŸå¼ƒå…¨å±€äº‹ä»¶ï¼Œæ”¹ç”¨ Channel ç›´è¿)
  // unlistenAudioChunk = await listen('tts-audio-chunk', (event) => { ... });
});

onUnmounted(() => {
  window.removeEventListener('resize', initPosition);
  if (unlistenMessage) unlistenMessage();
  if (unlistenTyping) unlistenTyping();
  if (unlistenStreaming) unlistenStreaming();
  
  // æ¸…ç† Live2D èµ„æº
  if (live2dApp.value) {
    live2dApp.value.destroy(true, { children: true, texture: true });
    live2dApp.value = null;
  }
});

// å¤„ç†è¾“å…¥æ¡†é€»è¾‘
const handleKeyDown = (e) => {
  if (e.key === 'Enter' && !e.shiftKey) {
    e.preventDefault();
    handleSend();
  } else if (e.key === 'Escape') {
    emit('close');
  } else if (e.key === 'v' && e.altKey) {
    e.preventDefault();
    if (isRecording.value) {
      stopRecording();
    } else {
      startRecording();
    }
  }
};

// ğŸš€ [è¿æ¥é¢„çƒ­] åªè¦ç”¨æˆ·å¼€å§‹è¾“å…¥ï¼Œå°±æ‚„æ‚„é¢„çƒ­è¿æ¥
let prewarmTimer = null;
watch(inputText, (newVal) => {
  if (newVal.trim().length >= 1) {
    if (prewarmTimer) clearTimeout(prewarmTimer);
    prewarmTimer = setTimeout(async () => {
      try {
        const config = configStore.settings;
        const providerId = config.defaultProvider_id;
        const provider = config.providers?.find(p => p.id === providerId);
        if (provider?.baseUrl) {
          invoke('prewarm_connection', { baseUrl: provider.baseUrl });
        }
      } catch (e) {}
    }, 300);
  }
});

const handleSend = async () => {
  const text = inputText.value.trim();
  if (!text || isSending.value) return;

  // ğŸš€ [ä¼˜åŒ–] é¢„çƒ­éŸ³é¢‘å¼•æ“ + ç½‘ç»œ
  initAudioContext();
  try {
     const config = configStore.settings;
     const provider = config.providers?.find(p => p.id === config.defaultProviderId);
     if (provider?.baseUrl) invoke('prewarm_connection', { baseUrl: provider.baseUrl });
  } catch(e) {}

  // ğŸš€ [æ€§èƒ½ç›‘æµ‹] è®°å½•å¼€å§‹å‘é€æ—¶é—´
  perfMetrics.value.sendTime = performance.now();
  perfMetrics.value.hasTrackedLLM = false;
  perfMetrics.value.hasTrackedTTS = false;
  
  // ğŸš€ æ¸…ç©ºä¹‹å‰çš„å­—å¹•å†…å®¹ï¼Œå‡†å¤‡æ¥æ”¶æ–°æµ
  subtitleText.value = '';
  
  // ğŸ¤ æ¸…ç©º TTS é˜Ÿåˆ—å’Œç´¯ç§¯æ–‡æœ¬
  stopAllTTS();
  accumulatedText.value = '';
  isStreamingDone.value = false;
  
  // ğŸš€ [V3] é‡ç½®åºåˆ—ç´¢å¼•ä¸ç¼“å†²åŒº
  nextAssignIndex.value = 0;
  nextToDeliverIndex.value = 0;
  pendingAudioMap.value.clear();
  sentenceBuffer.value = '';
  
  // ğŸš€ [V2] äº§ç”Ÿæ–°çš„è¯·æ±‚ ID,è®©æ—§çš„åå°ä»»åŠ¡å¤±æ•ˆ
  try {
    currentRequestId.value = await invoke('next_tts_request_id');
    currentSessionToken.value = Math.random().toString(36).substring(7);
    isWaitingForResponse.value = true; // å¼€å§‹ç­‰å¾…æ–°çš„ä¸€è½®
  } catch(e) {
    console.warn('è·å–è¯·æ±‚ ID å¤±è´¥:', e);
  }
  
  try {
    isSending.value = true;
    
    // 1. å‘é€æ¶ˆæ¯åˆ°åç«¯å¹¶è·å–çœŸæ­£çš„æ•°æ®åº“ ID
    const msgId = await invoke('save_social_message', {
      contactId: chatStore.activeSocialContactId,
      sessionId: chatStore.activeSocialSessionId,
      role: 'user',
      content: text,
      fileMetadata: null
    });

    // 2. å…¨å±€åŒæ­¥ï¼šç¡®ä¿å­—æ®µä¸ SocialChatContainer.vue é‡Œçš„ç›‘å¬å™¨å®Œå…¨åŒ¹é…
    const msgData = {
        messageId: msgId, // å¿…é¡»åŒ…å« IDï¼Œå¦åˆ™ä¸»ç•Œé¢ä¼šå› ä¸ºæ‰¾ä¸åˆ° ID è€ŒåŒæ­¥å¤±è´¥
        contactId: chatStore.activeSocialContactId,
        sessionId: chatStore.activeSocialSessionId,
        role: 'user',
        content: text,
        createdAt: new Date().toISOString() // è¿™é‡Œçš„å˜é‡åä¹Ÿè¦æ³¨æ„
    };

    // å‘å°„ç»™çˆ¶ç»„ä»¶
    emit('send', msgData);
    
    // å…³é”®ä¿®å¤ï¼šå‘å°„å…¨å±€äº‹ä»¶ï¼Œç¡®ä¿å­—æ®µåç¬¦åˆ SocialChatContainer çš„è§£æ„é€»è¾‘
    await tauriEmit('new-social-message', {
        ...msgData,
        created_at: msgData.createdAt // ä¸»ç•Œé¢ç”¨çš„æ˜¯ created_at
    });

    // 3. è§¦å‘æ²‰æµ¸å¼å›å¤é€»è¾‘
    if (configStore.settings.chatMode?.enabled) {
      // ğŸš€ [æ€§èƒ½ç›‘æµ‹] è®°å½•å¼€å§‹è¯·æ±‚ AI çš„æ—¶é—´
      perfMetrics.value.ttsRequestStartTime = performance.now(); // åˆæ­¥è®°å½•ï¼Œä¼šè¢«åé¢çš„è¦†ç›–
      
      await invoke('send_social_message_immersive', {
        sessionId: chatStore.activeSocialSessionId,
        contactId: chatStore.activeSocialContactId,
        content: text
      });
    }

    // 4. æ¸…ç©ºè¾“å…¥æ¡†å¹¶ç¡®ä¿ç„¦ç‚¹ä¿æŒ
    inputText.value = '';
    await nextTick();
    inputRef.value?.focus();
  } catch (e) {
    console.error('Failed to send:', e);
  } finally {
    isSending.value = false;
  }
};

// è¯­éŸ³å½•åˆ¶é€»è¾‘
const startRecording = async () => {
  try {
    // â“ 0. é¢„æ£€æŸ¥ & ç¡®è®¤ä¸‹è½½
    try {
        const status = await invoke('check_asr_model_status');
        
        if (status === 'READY') {
             // 2. æ­£å¼å¼€å§‹å½•éŸ³
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioChunks.value = [];
            
            mediaRecorder.value = new MediaRecorder(stream);
            mediaRecorder.value.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.value.push(event.data);
            }
            };
            
            mediaRecorder.value.onstop = async () => {
            const audioBlob = new Blob(audioChunks.value, { type: 'audio/webm' });
            await processAudio(audioBlob);
            stream.getTracks().forEach(track => track.stop());
            };
            
            mediaRecorder.value.start();
            isRecording.value = true;
            console.log('[ç³»ç»Ÿ] å¼€å§‹å½•éŸ³');
            return;
        }

        // å¦‚æœæœªå°±ç»ªï¼Œåˆ™æç¤ºä¸‹è½½
        const confirmed = await ask(
            'é¦–æ¬¡ä½¿ç”¨è¯­éŸ³åŠŸèƒ½éœ€è¦ä¸‹è½½ AI æ¨¡å‹ç»„ä»¶ï¼ˆçº¦ 200MBï¼‰ã€‚\n\nç‚¹å‡»â€œç¡®å®šâ€å¼€å§‹ä¸‹è½½ï¼Œä¸‹è½½è¿‡ç¨‹ä¸­è¯·ä¿æŒç½‘ç»œè¿æ¥ã€‚', 
            { title: 'ä¸‹è½½ç¡®è®¤', kind: 'info', okLabel: 'ç«‹å³ä¸‹è½½', cancelLabel: 'æš‚ä¸ä¸‹è½½' }
        );
        
        if (!confirmed) return;

    } catch (e) {
        console.error("Failed to check model status:", e);
        return;
    }

    // 1. æ£€æŸ¥ ASR æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è§¦å‘ä¸‹è½½
    isDownloadingModel.value = true;
    downloadProgress.value = 0;
    downloadStatusText.value = 'æ­£åœ¨æ£€æŸ¥ AI ç»„ä»¶å®Œæ•´æ€§...';

    // ç›‘å¬è¿›åº¦äº‹ä»¶
    const unlisten = await listen('ASR_DOWNLOAD_PROGRESS', (event) => {
        const { percent, file, total, downloaded } = event.payload;
        downloadProgress.value = Math.round(percent);
        downloadStatusText.value = `æ­£åœ¨ä¸‹è½½ ${file}...`;
        
        // æ ¼å¼åŒ–å¤§å°
        const toMB = (bytes) => (bytes / 1024 / 1024).toFixed(1);
        if (total > 0) {
            downloadDetail.value = `${toMB(downloaded)} MB / ${toMB(total)} MB`;
        } else {
             downloadDetail.value = `${toMB(downloaded)} MB / ???`;
        }
    });

    try {
        await invoke('download_asr_model');
    } catch (e) {
        console.error('Model download failed:', e);
        downloadStatusText.value = `ä¸‹è½½å¤±è´¥: ${e}`;
        // åœç•™ 3 ç§’è®©ç”¨æˆ·çœ‹æ¸…é”™è¯¯
        await new Promise(r => setTimeout(r, 3000));
        isDownloadingModel.value = false;
        unlisten();
        return; 
    }

    unlisten();
    isDownloadingModel.value = false;
    
    // ğŸš€ 2. ä¸‹è½½å®Œæˆï¼Œæç¤ºç”¨æˆ·é‡æ–°ç‚¹å‡» (ä¸å†è‡ªåŠ¨å¼€å§‹å½•éŸ³)
    await message("AI æ¨¡å‹ç»„ä»¶å·²ä¸‹è½½å®Œæˆï¼Œè¯·å†æ¬¡ç‚¹å‡»éº¦å…‹é£å¼€å§‹è¯´è¯ã€‚", { title: "ä¸‹è½½æˆåŠŸ", kind: 'info' });
  } catch (e) {
    console.error('å½•éŸ³å¯åŠ¨å¤±è´¥:', e);
  }
};

const stopRecording = () => {
  if (mediaRecorder.value && isRecording.value) {
    mediaRecorder.value.stop();
    isRecording.value = false;
    console.log('[ç³»ç»Ÿ] åœæ­¢å½•éŸ³');
  }
};

const processAudio = async (audioBlob) => {
  try {
    const arrayBuffer = await audioBlob.arrayBuffer();
    const audioContext = new AudioContext({ sampleRate: 16000 });
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    
    // è½¬æ¢ä¸ºå•å£°é“ PCM
    const pcmData = audioBuffer.getChannelData(0);
    const samples = Array.from(pcmData);
    
    console.log('[ASR] å‘é€éŸ³é¢‘, æ ·æœ¬æ•°:', samples.length);
    
    const text = await invoke('transcribe_pcm', {
      samples,
      sampleRate: 16000
    });
    
    if (text && text.trim()) {
      inputText.value = text;
      await nextTick();
      inputRef.value?.focus();
    }
  } catch (e) {
    console.error('éŸ³é¢‘å¤„ç†å¤±è´¥:', e);
  }
};

// ğŸš€ [æ€§èƒ½ä¼˜åŒ–] çª—å£æ‹–æ‹½åŒæ ·ä½¿ç”¨åŸç”Ÿ + RAF
const startDragging = (e) => {
  isDragging.value = true;
  dragOffset.value = {
    x: e.clientX - windowPos.value.x,
    y: e.clientY - windowPos.value.y
  };
  
  let rafId = null;
  const onMove = (me) => {
    if (rafId) return;
    rafId = requestAnimationFrame(() => {
      windowPos.value = {
        x: me.clientX - dragOffset.value.x,
        y: me.clientY - dragOffset.value.y
      };
      rafId = null;
    });
  };
  
  const stopDragging = () => {
    isDragging.value = false;
    document.removeEventListener('mousemove', onMove);
    document.removeEventListener('mouseup', stopDragging);
    if (rafId) cancelAnimationFrame(rafId);
  };
  
  document.addEventListener('mousemove', onMove);
  document.addEventListener('mouseup', stopDragging);
};

// ğŸš€ [æµæ°´çº¿] åœé¡¿æ£€æµ‹å™¨ï¼šå¦‚æœ AI åœæ­¢åå­—ï¼Œç«‹å³å¼ºåˆ¶è¯»å‡ºå½“å‰ç¼“å­˜
const startInactivityTimer = () => {
    clearTimeout(inactivityTimer.value);
    inactivityTimer.value = setTimeout(() => {
        if (accumulatedText.value.trim() || sentenceBuffer.value.trim()) {
            console.log('[TTS] [æµæ°´çº¿] åœé¡¿è§¦å‘ (300ms æº¢å‡º)');
            flushSentenceBuffer();
        }
    }, INACTIVITY_TIMEOUT);
};

// ğŸš€ [è¯­è¨€æ£€æµ‹è¾…åŠ©] æ£€æµ‹æ˜¯å¦åŒ…å«æ—¥æ–‡å‡å
const detectLanguage = (t) => {
    // æ—¥æ–‡å‡åèŒƒå›´: å¹³å‡å 3040-309F, ç‰‡å‡å 30A0-30FF
    if (/[\u3040-\u309F\u30A0-\u30FF]/.test(t)) return 'ja';
    return 'zh';
};

// ğŸ¤ [TTS åŠŸèƒ½] æ£€æµ‹å¥å­ç»“æŸå¹¶ç”Ÿæˆ TTS
const checkAndGenerateTTS = () => {
  let text = accumulatedText.value;
  const sentenceEndRegex = /[ã€‚ï¼ï¼Ÿ!?ï¼›ï¼Œ, \nã€]/;
  
  // ğŸš€ [åŠ¨æ€é˜ˆå€¼è®¡ç®—]
  const getThreshold = (index) => {
      if (index === 0) return MIN_FIRST_SENTENCE_LENGTH; // 6
      return MIN_SENTENCE_LENGTH; // 18
  };

  // 1. ä¼˜å…ˆå¤„ç†å¼ºæ ‡ç‚¹ç¬¦å· (è‡ªç„¶æ–­å¥)
  let match;
  while ((match = text.match(sentenceEndRegex)) !== null) {
    const mark = match[0];
    const endIndex = text.indexOf(mark) + 1;
    const sentence = text.substring(0, endIndex).trim();
    
    if (sentence.length > 0) {
      sentenceBuffer.value += sentence;
      const currentThreshold = getThreshold(nextAssignIndex.value);
      
      if (sentenceBuffer.value.length >= currentThreshold || /[ã€‚ï¼ï¼Ÿ!?ï¼›,ï¼Œ\n]/.test(mark)) {
          console.log(`[TTS] [æ ‡ç‚¹è§¦å‘] åºå·: ${nextAssignIndex.value}, é•¿åº¦: ${sentenceBuffer.value.length}`);
          const seqIdx = nextAssignIndex.value;
          nextAssignIndex.value++;
          generateTTSForSentence(sentenceBuffer.value, seqIdx);
          sentenceBuffer.value = '';
      }
    }
    text = text.substring(endIndex);
  }
  
  // 2. ğŸš€ [è¯­ä¹‰åˆ†è¯å¼ºåˆ¶åˆ‡åˆ†] å¦‚æœæ²¡æœ‰æ ‡ç‚¹ï¼Œä½†ç´¯ç§¯åˆ°ä¸€å®šé•¿åº¦ï¼Œå¯»æ‰¾æœ€è¿‘çš„è¯è¾¹ç•Œ
  const threshold = getThreshold(nextAssignIndex.value);
  if (text.length >= threshold) {
      const segments = Array.from(segmenter.segment(text));
      let splitIdx = -1;

      for (const seg of segments) {
          const segEnd = seg.index + seg.segment.length;
          // è¯­ä¹‰è§„åˆ™ï¼šè·¨è¿‡é˜ˆå€¼çš„ç¬¬ä¸€ä¸ªâ€œè¯ç»“æŸâ€ä½ç½®å°±æ˜¯æœ€ä½³åˆ‡åˆ†ç‚¹
          if (segEnd >= threshold) {
              splitIdx = segEnd;
              break;
          }
      }

      if (splitIdx !== -1) {
          // æ®‹ç•™ä¿æŠ¤ï¼šå¦‚æœåˆ‡å®Œå‰©ä¸‹çš„å­—æ•°å¤ªå°‘ï¼ˆ< 4ï¼‰ï¼Œä¸” AI è¿˜åœ¨åå­—ï¼Œåˆ™æš‚ç¼“
          if (text.length - splitIdx < 4 && !isStreamingDone.value) {
              // æ†‹ç€ï¼Œç­‰ä¸‹ä¸€æ¬¡
          } else {
              const sentence = text.substring(0, splitIdx);
              console.log(`[TTS] [åˆ†è¯è§¦å‘] åºå·: ${nextAssignIndex.value}, é•¿åº¦: ${sentence.length}, è§¦å‘è¯: "${sentence.slice(-2)}"`);
              const seqIdx = nextAssignIndex.value;
              nextAssignIndex.value++;
              generateTTSForSentence(sentence, seqIdx);
              text = text.substring(splitIdx);
          }
      }
  }
  
  accumulatedText.value = text;
  startInactivityTimer();
};

// è®°å½•æµæ˜¯å¦ç»“æŸï¼Œæ–¹ä¾¿ checkAndGenerateTTS åˆ¤æ–­
const isStreamingDone = ref(false);

const flushSentenceBuffer = () => {
    // 1. åˆå¹¶ residue
    if (accumulatedText.value.trim()) {
        sentenceBuffer.value += accumulatedText.value;
        accumulatedText.value = '';
    }
    
    // 2. å‘é€
    if (sentenceBuffer.value.trim()) {
        const seqIdx = nextAssignIndex.value;
        nextAssignIndex.value++;
        generateTTSForSentence(sentenceBuffer.value.trim(), seqIdx);
        sentenceBuffer.value = '';
    }
    clearTimeout(inactivityTimer.value);
};

// ğŸ¤ [TTS åŠŸèƒ½] ä¸ºå•ä¸ªå¥å­ç”Ÿæˆ TTS
const generateTTSForSentence = async (sentence, sequenceIndex) => {
  const taskId = currentRequestId.value;
  const sessionToken = currentSessionToken.value;

  // ğŸš€ [æ€§èƒ½ç›‘æµ‹] è®°å½•å‘åç«¯å‘èµ·è¯·æ±‚çš„æ—¶é—´ (ä»…é’ˆå¯¹ç¬¬ä¸€æ®µ)
  if (Number(sequenceIndex) === 0) {
      perfMetrics.value.ttsRequestStartTime = performance.now();
  }

  try {
    console.log(`[TTS] [å¼€å§‹] è¯·æ±‚æœ¬åœ° TTS (ID: ${taskId}, åºå·: ${sequenceIndex}):`, sentence);
    
    // ğŸš€ [æ ¸å¿ƒ] è°ƒç”¨åç«¯æœ¬åœ° TTS
    // ğŸš€ [å…³é”®ä¿®å¤] å…ˆåˆ›å»ºå¹¶åœ¨é˜Ÿåˆ—ä¸­é¢„ä½ï¼Œå†æ‰§è¡Œ invoke
    // å¦åˆ™ invoke é˜»å¡æœŸé—´åˆ°è¾¾çš„ chunk ä¼šå› ä¸ºæ‰¾ä¸åˆ° audioItem è€Œè¢«ä¸¢å¼ƒ
    const audioItem = {
      sentence,
      audioData: 'STREAMING', 
      taskId,
      sequenceIndex,
      chunks: [],
      isDone: false,
      sampleRate: 0, // ğŸš€ [æ–°å¢] åŠ¨æ€å­˜å‚¨æ¢æµ‹åˆ°çš„é‡‡æ ·ç‡
      language: detectLanguage(sentence) // ğŸš€ [æ–°å¢] è‡ªåŠ¨æ£€æµ‹è¯­è¨€
    };

    // ğŸš€ [ä¸¥æ ¼äº¤ä»˜] ä»…åœ¨åºå·å¯¹é½æ—¶å…¥é˜Ÿ
    if (sequenceIndex === nextToDeliverIndex.value) {
      console.log(`[TTS] åºå· ${sequenceIndex} å¯¹é½, åˆ›å»ºéŸ³é¢‘é¡¹`);
      audioQueue.value.push(audioItem);
      nextToDeliverIndex.value++;
      
      // çº§è”å¤„ç†æš‚å­˜åŒº
      while (pendingAudioMap.value.has(nextToDeliverIndex.value)) {
        const nextItem = pendingAudioMap.value.get(nextToDeliverIndex.value);
        audioQueue.value.push(nextItem);
        pendingAudioMap.value.delete(nextToDeliverIndex.value);
        nextToDeliverIndex.value++;
      }
      
      if (!isPlayingAudio.value) {
        playNextAudio();
      }
    } else {
      console.log(`[V5-STREAM] åºåˆ— ${sequenceIndex} ä¹±åºåˆ°è¾¾, æš‚å­˜å…¥åº“`);
      pendingAudioMap.value.set(sequenceIndex, audioItem);
    }

    // ğŸš€ [V6] æ”¹ä¸ºå…¥é˜Ÿå¤„ç†ï¼Œä¸å†ç›´æ¥ await invoke
    return new Promise((resolve, reject) => {
        ttsRequestQueue.value.push({
            sentence,
            taskId,
            sequenceIndex,
            audioItem,
            resolve,
            reject
        });
        console.log(`[TTS] [å…¥é˜Ÿ] è¯·æ±‚å·²åŠ å…¥é˜Ÿåˆ— (åºå·: ${sequenceIndex}), ç­‰å¾…å¤„ç†...`);
        processTTSQueue();
    });

  } catch (e) {
    console.error('[V5-STREAM] TTS ç”Ÿæˆè§¦å‘å¤±è´¥:', e);
    // è¿™é‡Œå¦‚æœå¤±è´¥äº†ï¼Œç†æƒ³æƒ…å†µä¸‹åº”è¯¥æŠŠé¢„å çš„ item æ ‡è®°ä¸º done ä»¥è·³è¿‡
  }
};

// ğŸš€ [V5] è®°å½•å½“å‰æ­£åœ¨æµå¼æ’­æ”¾çš„åºå·
// const currentStreamingSequence = ref(-1); // å·²ç§»åŠ¨åˆ°ä¸Šæ–¹é¡¶å±‚

// ğŸ¤ [TTS åŠŸèƒ½] æ’­æ”¾é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªéŸ³é¢‘
const playNextAudio = async () => {
  // ğŸš€ [ä¿®å¤] å¦‚æœå·²ç»åœ¨æ’­æ”¾ï¼Œä¸å…è®¸å¤šæ¬¡è§¦å‘ï¼Œé˜²æ­¢é€»è¾‘å†²çª
  if (isPlayingAudio.value && currentStreamingSequence.value !== -1) {
      console.log('[V4-CORE] å·²ç»åœ¨æ’­æ”¾æµå¼éŸ³é¢‘ï¼Œè·³è¿‡è§¦å‘');
      return;
  }

  if (audioQueue.value.length === 0) {
    isPlayingAudio.value = false;
    isSpeaking.value = false;
    currentAudioElement.value = null;
    currentStreamingSequence.value = -1;
    return;
  }
  
  // å®‰å…¨æ ¡éªŒï¼šæ¸…é™¤è¿‡æœŸä»»åŠ¡
  if (audioQueue.value[0].taskId !== currentRequestId.value) {
      console.warn('[V4-CORE] æ¸…ç†è¿‡æœŸé˜Ÿåˆ—ä»»åŠ¡');
      audioQueue.value = [];
      isPlayingAudio.value = false;
      isSpeaking.value = false;
      return;
  }

  const audioItem = audioQueue.value[0]; 
  isPlayingAudio.value = true;
  
  try {
    if (audioItem.audioData === 'STREAMING') {
        console.log('[V5] å¯åŠ¨æµå¼æ’­æ”¾:', audioItem.sentence);
        
        // ğŸš€ [å…³é”®ä¿®å¤] å…ˆå‘å¸ƒçŠ¶æ€ï¼Œå Await ç¡¬ä»¶ã€‚é˜²æ­¢ Await æœŸé—´æ¥çš„ Chunk åŒ¹é…å¤±è´¥ã€‚
        currentStreamingSequence.value = Number(audioItem.sequenceIndex);
        isPlayingAudio.value = true;
        isSpeaking.value = true;

        await initAudioContext();
        
        // ğŸš€ [ä¼˜åŒ–] è¡”æ¥é€»è¾‘ï¼šå¦‚æœå½“å‰æ—¶é—´ç¦»ä¸Šä¸€æ¬¡è°ƒåº¦ç»“æŸè¿˜æ²¡è¶…è¿‡ 0.5 ç§’ï¼Œåˆ™ç»§ç»­è¿½åŠ è°ƒåº¦ï¼Œå®ç°æ— ç¼è¡”æ¥ã€‚
        const now = audioCtx.value.currentTime;
        if (nextChunkTime.value < now || nextChunkTime.value > now + 2.0) {
            console.log('[V5] é‡æ–°æ ¡å‡†éŸ³é¢‘è°ƒåº¦æ—¶é—´è½´ (æé€Ÿæ¨¡å¼)');
            nextChunkTime.value = now + 0.01; // ğŸš€ [ä¼˜åŒ–] 0.05s -> 0.01s æé™ä½å»¶è¿Ÿ
        } else {
            console.log(`[V5] æ²¿ç”¨ç°æœ‰æ—¶é—´è½´ï¼Œåç§»: ${(nextChunkTime.value - now).toFixed(3)}s`);
        }

        // æ’­æ”¾ç°æœ‰çš„ç¼“å­˜ chunks
        console.log(`[V5] è¡¥æ’­ç¼“å­˜ Chunks: ${audioItem.chunks.length} ä¸ª, é‡‡æ ·ç‡: ${audioItem.sampleRate || 32000}Hz`);
        while (audioItem.chunks.length > 0) {
            schedulePCMChunk(audioItem.chunks.shift(), audioItem.sampleRate || 32000);
        }

        // æŒç»­æ£€æµ‹æ˜¯å¦ç»“æŸ
        let lastCheckTime = Date.now();
        let lastLength = -1;
        
        const checkEnd = () => {
            // ğŸš€ [å®‰å…¨è¡¥å¿] æ¶ˆè´¹å¯èƒ½é”™è¿‡çš„ chunks (é˜²æ­¢ç«æ€)
            while (audioItem.chunks.length > 0) {
                console.log('[V5] checkEnd è¡¥æ’­é”™è¿‡çš„é¡¹');
                schedulePCMChunk(audioItem.chunks.shift());
            }

            const isDone = audioItem.isDone && audioItem.chunks.length === 0;
            const now = Date.now();
            
            // ğŸš€ [å®‰å…¨é€€å‡º] å¦‚æœ 5 ç§’é’Ÿæ²¡æœ‰æ–°æ•°æ®ä¸”å·²æ ‡è®° Doneï¼Œå¼ºè¡Œç»“æŸï¼Œé˜²æ­¢å› ä¸ºé€»è¾‘ Bug å¡æ­»
            const isTimeout = audioItem.isDone && (now - lastCheckTime > 5000);
            
            if (isDone || isTimeout) {
                if (isTimeout) console.warn('[V5] æ£€æµ‹åˆ°æ’­æ”¾è¶…æ—¶ï¼Œå¼ºè¡Œåˆ‡æ¢ä¸‹ä¸€æ®µ');
                
                // ç­‰å¾…æœ€åä¸€æ®µæ’­å®Œ
                const waitTime = Math.max(0, (nextChunkTime.value - audioCtx.value.currentTime) * 1000 + 50);
                setTimeout(() => {
                    console.log('[V5] æµå¼æ®µç»“æŸï¼Œåˆ‡æ¢ä¸‹ä¸€æ®µ');
                    audioQueue.value.shift(); // æ¶ˆè´¹æ‰
                    isPlayingAudio.value = false; 
                    playNextAudio();
                }, waitTime);
            } else {
                if (audioItem.chunks.length !== lastLength) {
                    lastCheckTime = now;
                    lastLength = audioItem.chunks.length;
                }
                setTimeout(checkEnd, 100);
            }
        };
        checkEnd();

    } else {
        audioQueue.value.shift(); // æ™®é€šæ¨¡å¼å…ˆæ¶ˆè´¹
        let url;
        const isRemote = audioItem.audioData.startsWith('URL:');
        
        // ğŸš€ [ä¿®å¤] æ£€æµ‹æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
        const isLocalFile = /^[a-zA-Z]:\\/.test(audioItem.audioData) || audioItem.audioData.includes('\\') || audioItem.audioData.startsWith('/');

        if (isRemote) {
          url = audioItem.audioData.substring(4);
          console.log('[V4-CORE] å¯åŠ¨è¿œç¨‹æµæ’­æ”¾:', audioItem.sentence, url);
        } else if (isLocalFile) {
          url = convertFileSrc(audioItem.audioData);
          console.log('[V4-CORE] å¯åŠ¨æœ¬åœ°æ–‡ä»¶æ’­æ”¾:', audioItem.sentence, url);
        } else {
          const blob = base64ToBlob(audioItem.audioData, 'audio/wav');
          url = URL.createObjectURL(blob);
          console.log('[V4-CORE] å¯åŠ¨æœ¬åœ°äºŒè¿›åˆ¶æ’­æ”¾:', audioItem.sentence);
        }
        
        const audio = new Audio(url);
        audio.volume = 1.0; 
        currentAudioElement.value = audio;
        
        audio.onplay = () => {
          console.log('[V4-CORE] éŸ³é¢‘å¼€å§‹è¾“å‡ºï¼Œè§¦å‘åŠ¨å˜´åŠ¨ç”»');
          isSpeaking.value = true;
        };

        audio.onended = () => {
          console.log('[V4-CORE] æ’­æ”¾å®Œæˆ:', audioItem.sentence);
          if (!isRemote) URL.revokeObjectURL(url);
          isSpeaking.value = false;
          setTimeout(playNextAudio, 50); 
        };
        
        audio.onerror = (e) => {
          console.error('[V4-CORE] éŸ³é¢‘åŠ è½½/æ’­æ”¾å¤±è´¥:', e, url);
          if (!isRemote) URL.revokeObjectURL(url);
          isSpeaking.value = false;
          playNextAudio();
        };
        
        audio.play().catch(e => {
          console.error('[V4-CORE] è‡ªåŠ¨æ’­æ”¾è¢«æ‹¦æˆªæˆ–å¤±è´¥:', e);
          isSpeaking.value = false;
          playNextAudio();
        });
    }
  } catch (err) {
    console.error('[V4-CORE] æ’­æ”¾åˆå§‹åŒ–å¼‚å¸¸:', err);
    playNextAudio();
  }
};


// ğŸš€ [V5] Base64 è½¬ ArrayBuffer
const base64ToArrayBuffer = (base64) => {
    const binary = window.atob(base64);
    const len = binary.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
        bytes[i] = binary.charCodeAt(i);
    }
    return bytes.buffer;
};

// ğŸš€ [V5] è°ƒåº¦ PCM é‡‡æ ·æ’­æ”¾
const schedulePCMChunk = (arrayBuffer, sampleRate = 32000) => {
    if (!audioCtx.value) {
        console.warn('[TTS] AudioContext æœªåˆå§‹åŒ–ï¼Œæ”¾å¼ƒè°ƒåº¦ Chunk');
        return;
    }
    
    // è‡ªåŠ¨æ¢å¤ä¸Šä¸‹æ–‡ (é˜²æ­¢æŸäº›æµè§ˆå™¨ç”±äºéç‚¹å‡»è§¦å‘è€Œè¢«æŒ‚èµ·)
    if (audioCtx.value.state === 'suspended') {
        audioCtx.value.resume();
    }
    
    // ğŸš€ [ä¿®å¤æ ¸å¿ƒ] å­—èŠ‚å¯¹é½å¤„ç†
    let currentData = new Uint8Array(arrayBuffer);
    if (residualBuffer.value) {
        const combined = new Uint8Array(residualBuffer.value.length + currentData.length);
        combined.set(residualBuffer.value);
        combined.set(currentData, residualBuffer.value.length);
        currentData = combined;
        residualBuffer.value = null;
    }
    
    // å¦‚æœé•¿åº¦æ˜¯å¥‡æ•°ï¼Œä¿ç•™æœ€åä¸€ä¸ªå­—èŠ‚åˆ°ä¸‹ä¸€æ¬¡å¤„ç†
    if (currentData.length % 2 !== 0) {
        residualBuffer.value = currentData.slice(-1);
        currentData = currentData.slice(0, -1);
    }
    
    if (currentData.length === 0) return;

    // å°† Int16ï¼ˆ2å­—èŠ‚ï¼‰è½¬æ¢ä¸º Float32
    // è¯Šæ–­æ—¥å¿—ï¼šæ‰“å°å‰å‡ ä¸ªé‡‡æ ·å€¼
    const int16Array = new Int16Array(currentData.buffer, currentData.byteOffset, currentData.byteLength / 2);
    
    // ğŸš€ åŠ å¼ºæ—¥å¿—ï¼šå¦‚æœé‡‡æ ·å…¨ä¸º 0ï¼Œç‰¹åˆ«æŒ‡å‡º
    const isSilent = int16Array.every(v => v === 0);
    console.log(`[TTS] Chunk è°ƒåº¦: ${int16Array.length} samples, ç¬¬ä¸€ä¸ªé‡‡æ ·: ${int16Array[0]}${isSilent ? ' (âš ï¸ å…¨ç¨‹é™éŸ³!)' : ''}`);

    const float32Array = new Float32Array(int16Array.length);
    for (let i = 0; i < int16Array.length; i++) {
        float32Array[i] = int16Array[i] / 32768.0;
    }
    
    const audioBuffer = audioCtx.value.createBuffer(1, float32Array.length, sampleRate);
    audioBuffer.getChannelData(0).set(float32Array);
    
    const source = audioCtx.value.createBufferSource();
    source.buffer = audioBuffer;
    
    // ğŸš€ [ä¼˜åŒ–] æ˜¾å¼å¢åŠ  GainNode æ§åˆ¶éŸ³é‡
    const gainNode = audioCtx.value.createGain();
    gainNode.gain.value = 1.0; 
    
    source.connect(gainNode);
    gainNode.connect(audioCtx.value.destination);
    
    // å¢åŠ ä¸€ä¸ªæå°çš„å¹³æ»‘åç½®ï¼Œé˜²æ­¢ç”±äºè°ƒåº¦ç²¾åº¦å¯¼è‡´çš„çˆ†éŸ³
    const startTime = Math.max(audioCtx.value.currentTime, nextChunkTime.value);
    source.start(startTime);
    nextChunkTime.value = startTime + audioBuffer.duration;
};

// ğŸ¤ [TTS åŠŸèƒ½] åœæ­¢æ‰€æœ‰ TTS æ’­æ”¾
const stopAllTTS = () => {
  // åœæ­¢å½“å‰æ’­æ”¾
  if (currentAudioElement.value) {
    currentAudioElement.value.pause();
    currentAudioElement.value = null;
  }
  
  // æ¸…ç©ºé˜Ÿåˆ—
  audioQueue.value = [];
  isPlayingAudio.value = false;
  isSpeaking.value = false;
  
  // ğŸš€ [V3] æ¸…ç©ºåºåˆ—çŠ¶æ€
  nextAssignIndex.value = 0;
  nextToDeliverIndex.value = 0;
  pendingAudioMap.value.clear();
  sentenceBuffer.value = '';
  residualBuffer.value = null; // æ¸…ç©ºæ®‹ç•™ç¼“å†²
  currentStreamingSequence.value = -1;
  
  // ğŸš€ [V6] æ¸…ç©ºå¹¶å‘é˜Ÿåˆ—
  ttsRequestQueue.value = [];
  activeTTSRequests.value = 0; // é‡ç½®è®¡æ•°
  
  console.log('[TTS] å·²åœæ­¢æ‰€æœ‰æ’­æ”¾');
};

// ğŸ¤ [å·¥å…·å‡½æ•°] Base64 è½¬ Blob (æ¢å¤è¢«æ„å¤–åˆ é™¤çš„å‡½æ•°)
const base64ToBlob = (base64, type) => {
  const binaryString = window.atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return new Blob([bytes], { type });
};
</script>

<template>
  <div v-if="visible" class="minimalist-root">
    <!-- âœ¨ æ¨¡å‹ä¸‹è½½è¿›åº¦é®ç½© (ä½¿ç”¨é€šç”¨ç»„ä»¶) -->
    <ModelDownloadProgress 
        :visible="isDownloadingModel"
        :progress="downloadProgress"
        :status-text="downloadStatusText"
        :detail-text="downloadDetail"
    />

    <!-- Live2D Canvas å±‚ -->
    <canvas id="live2d-canvas" class="live2d-canvas"></canvas>
    
    <!-- å­—å¹•æ˜¾ç¤ºåŒºåŸŸ (å¤åˆ» ShowText) -->
    <div class="subtitle-area">
      <div class="subtitle-text" :class="{ 'is-typing': isTyping }">
        {{ subtitleText }}
      </div>
    </div>

    <!-- æ–‡æœ¬è¾“å…¥çª—å£ (å¤åˆ» TextWindow) -->
    <div 
        class="text-window" 
        :style="{ 
            left: windowPos.x + 'px', 
            top: windowPos.y + 'px',
            width: inputWidth + 'px',
            cursor: isDragging ? 'grabbing' : 'default'
        }"
    >
      <div class="h-layout">
        <input
          ref="inputRef"
          v-model="inputText"
          class="q-line-edit"
          placeholder="è¾“å…¥æ–‡å­—åæŒ‰å›è½¦..."
          @keydown="handleKeyDown"
          @mousedown.stop
          @click="() => console.log('[MinimalistOverlay] è¾“å…¥æ¡†è¢«ç‚¹å‡»')"
          @focus="() => console.log('[MinimalistOverlay] è¾“å…¥æ¡†è·å¾—ç„¦ç‚¹')"
          :disabled="isSending"
        />
        <div 
            class="voice-button" 
            :class="{ 'recording': isRecording }"
            @mousedown.stop="startRecording"
            @mouseup="stopRecording"
            @mouseleave="stopRecording"
            title="æŒ‰ä½è¯´è¯ (Alt+V)"
        >
          {{ isRecording ? 'ğŸ”´' : 'ğŸ¤' }}
        </div>
        <div 
            class="drag-button" 
            @mousedown.stop="onWindowMouseDown"
            title="æ‹–åŠ¨ä½ç½®"
        >
          â‹®â‹®
        </div>
      </div>
    </div>

    <!-- é€€å‡ºæç¤º -->
    <div class="exit-hint">
        æŒ‰ Esc æˆ–ç‚¹å‡»å¯¼èˆªæ æŒ‰é’®é€€å‡ºæç®€æ¨¡å¼
    </div>
  </div>
</template>


