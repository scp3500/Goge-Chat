use crate::commands::config_cmd;
use crate::memory::processor::{get_relevant_context, MemoryState};
use crate::models::{ChatRequest, Message};
use futures_util::StreamExt;
use serde::Serialize;
use serde_json::{json, Value};
use std::sync::atomic::Ordering;
use std::sync::Arc;
use tauri::{ipc::Channel, AppHandle, Emitter, State, Window};
use tokio::sync::RwLock;

#[tauri::command]
pub async fn ask_ai(
    app: AppHandle,
    state: State<'_, crate::GoleState>,
    memory_state: State<'_, Arc<RwLock<MemoryState>>>,
    msg: Vec<Message>,
    on_event: Channel<String>,
    window: Window,
    temperature: Option<f32>,
    max_tokens: Option<u32>,
    stream: Option<bool>,
    // ğŸŸ¢ æ–°å¢ï¼šå…è®¸å‰ç«¯æ˜¾å¼ä¼ å…¥å½“å‰ç»˜ç”»çš„ provider å’Œ model
    explicit_provider_id: Option<String>,
    explicit_model_id: Option<String>,
    client: State<'_, reqwest::Client>,
) -> Result<(), String> {
    // 1. åŠ è½½é…ç½®
    let config = config_cmd::load_config(app).await?;

    // 2. ç¡®å®šå½“å‰ä½¿ç”¨çš„æ¨¡å‹å’Œæä¾›å•†
    // ä¼˜å…ˆä½¿ç”¨æ˜¾å¼ä¼ å…¥çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰ï¼ˆæ—§ç‰ˆå‰ç«¯ï¼‰ï¼Œåˆ™å›é€€åˆ°å…¨å±€é…ç½®
    let selected_model = explicit_model_id.unwrap_or(config.selected_model_id.clone());
    let selected_provider_id = explicit_provider_id.unwrap_or(config.default_provider_id.clone());

    // ä» providers æ•°ç»„ä¸­æ‰¾åˆ°å½“å‰é€‰ä¸­çš„æä¾›å•†é…ç½®
    let providers = config
        .providers
        .as_array()
        .ok_or("é…ç½®é”™è¯¯ï¼šæ— æ³•è¯»å–æä¾›å•†åˆ—è¡¨")?;
    let provider_config = providers
        .iter()
        .find(|p| p["id"].as_str() == Some(&selected_provider_id))
        .ok_or(format!("æ‰¾ä¸åˆ°æä¾›å•†é…ç½®: {}", selected_provider_id))?;

    let api_key = provider_config["apiKey"].as_str().unwrap_or("").to_string();
    let base_url = provider_config["baseUrl"]
        .as_str()
        .unwrap_or("https://api.deepseek.com")
        .to_string();

    if api_key.trim().is_empty() {
        return Err(format!(
            "{} çš„ API Key æœªé…ç½®ï¼Œè¯·å‰å¾€è®¾ç½®é¡µé¢å¡«å†™",
            provider_config["name"].as_str().unwrap_or("è¯¥æä¾›å•†")
        ));
    }

    let messages = msg;

    // æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶ä½¿ç”¨æ¨ç† (å¦‚æœç”¨æˆ·æ‰‹åŠ¨è¾“å…¥äº† [REASON] æ ‡è®°)
    let has_reason_tag = messages
        .iter()
        .any(|m| m.role == "user" && m.content.contains("[REASON]"));

    let model = if has_reason_tag {
        // å¦‚æœæœ‰æ ‡è®°ä¸”æ˜¯ DeepSeekï¼Œåˆ‡æ¢åˆ° reasoner
        if selected_provider_id == "deepseek" {
            "deepseek-reasoner".to_string()
        } else {
            selected_model
        }
    } else {
        selected_model
    };

    // é¢„å¤„ç†æ¶ˆæ¯
    let mut clean_msgs = messages.clone();

    if let Some(m) = clean_msgs.last_mut() {
        if m.role == "user" && m.content.contains("[REASON]") {
            m.content = m.content.replace("[REASON]", "");
        }
        if m.role == "user" && m.content.contains("[SEARCH]") {
            let (original_query, provider) = if m.content.contains("[SEARCH:") {
                let start = m.content.find("[SEARCH:").unwrap();
                let end = m.content[start..].find(']').unwrap() + start;
                let provider = &m.content[start + 8..end];
                let clean = m.content.replace(&m.content[start..=end], "");
                (clean, provider.to_string())
            } else {
                (m.content.replace("[SEARCH]", ""), "all".to_string())
            };

            println!("ğŸ” æ­£åœ¨æ‰§è¡Œç½‘ç»œæœç´¢ (æº: {}): {}", provider, original_query);

            // å‘é€æœç´¢å¼€å§‹äº‹ä»¶
            let _ = window.emit(
                "search-status",
                json!({ "status": "searching", "query": original_query }),
            );

            match crate::commands::search::perform_search(
                &config.search_instance_url,
                &original_query,
                &provider,
            )
            .await
            {
                Ok(results) => {
                    println!("âœ… æœç´¢æˆåŠŸï¼Œè·å–åˆ° {} æ¡ç»“æœ", results.len());

                    // å‘é€æœç´¢ç»“æœäº‹ä»¶
                    let _ = window.emit(
                        "search-status",
                        json!({ "status": "done", "results": results }),
                    );

                    let mut context = String::from("ã€è”ç½‘æœç´¢å‚è€ƒèµ„æ–™ã€‘\n");
                    for (i, res) in results.iter().enumerate() {
                        context.push_str(&format!(
                            "{}. {}\n   é“¾æ¥: {}\n   å†…å®¹: {}\n\n",
                            i + 1,
                            res.title,
                            res.url,
                            res.snippet
                        ));
                    }

                    m.content = format!(
                        "ç”¨æˆ·åŸå§‹é—®é¢˜: {}\n\n{}\nè¯·åˆ†æä»¥ä¸Šæœç´¢ç»“æœï¼Œç»“åˆä½ çš„çŸ¥è¯†ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ä¸”æœ€æ–°çš„å›ç­”ã€‚",
                        original_query, context
                    );
                }
                Err(e) => {
                    println!("âŒ æœç´¢å¤±è´¥: {}", e);
                    let _ =
                        window.emit("search-status", json!({ "status": "error", "message": e }));
                }
            }
        }
    }

    // --- ğŸ§  Alice Memory Integration ---
    if let Some(last_user_msg) = messages.iter().rev().find(|m| m.role == "user") {
        let mode = last_user_msg.mode.as_deref().unwrap_or("Standard");
        let role_id = last_user_msg.role_id.as_deref().unwrap_or("default");

        let query = last_user_msg.content.clone();

        // å‘é€è®°å¿†æ£€ç´¢å¼€å§‹äº‹ä»¶
        let _ = window.emit(
            "memory-status",
            json!({ "status": "searching", "query": query }),
        );
        let start_time = std::time::Instant::now();

        let context =
            get_relevant_context(memory_state.inner().clone(), &query, mode, role_id).await?;

        let duration = start_time.elapsed().as_millis();

        if !context.is_empty() {
            println!(
                "ğŸ§  [è®°å¿†æ³¨å…¥] æ¨¡å¼: {}, è§’è‰²: {}, è€—æ—¶: {}ms (æ³¨å…¥ {} å­—ç¬¦)",
                mode,
                role_id,
                duration,
                context.len()
            );

            // å‘é€è®°å¿†æ£€ç´¢å®Œæˆäº‹ä»¶
            let _ = window.emit(
                "memory-status",
                json!({ "status": "done", "duration": duration, "has_context": true }),
            );
            // æ‰¾åˆ°ç³»ç»Ÿæç¤ºè¯å¹¶æ³¨å…¥
            if let Some(sys_msg) = clean_msgs.iter_mut().find(|m| m.role == "system") {
                sys_msg.content = format!("{}\n\n{}", context, sys_msg.content);
            } else {
                // å¦‚æœæ²¡æœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œåœ¨æœ€å‰é¢æ’å…¥ä¸€ä¸ª
                clean_msgs.insert(
                    0,
                    Message {
                        id: None,
                        model: None,
                        role: "system".to_string(),
                        content: context,
                        reasoning_content: None,
                        file_metadata: None,
                        search_metadata: None,
                        provider: None,
                        mode: None,
                        role_id: None,
                    },
                );
            }
        } else {
            // å‘é€è®°å¿†æ£€ç´¢å®Œæˆäº‹ä»¶ (æ— ç»“æœ)
            let _ = window.emit(
                "memory-status",
                json!({ "status": "done", "duration": duration, "has_context": false }),
            );
        }
    }

    let temperature =
        temperature.or_else(|| provider_config["temperature"].as_f64().map(|f| f as f32));
    let max_tokens = max_tokens.or_else(|| provider_config["maxTokens"].as_u64().map(|u| u as u32));

    // --- â¬‡ï¸ Google Gemini Native æ”¯æŒ â¬‡ï¸ ---
    if selected_provider_id == "gemini" {
        return handle_gemini_native(
            api_key,
            base_url,
            model,
            clean_msgs,
            state,
            on_event,
            stream.unwrap_or(true),
            &client,
        )
        .await;
    }
    // --- â¬†ï¸ Google Gemini Native æ”¯æŒ â¬†ï¸ ---

    let payload = ChatRequest {
        model: model.to_string(),
        messages: clean_msgs,
        stream: stream.unwrap_or(true),
        temperature,
        max_tokens,
    };

    let disable_url_suffix = provider_config["disableUrlSuffix"]
        .as_bool()
        .unwrap_or(false);

    let url = if disable_url_suffix {
        base_url.clone()
    } else {
        let base = base_url.trim_end_matches('/');
        if base.ends_with("/chat/completions") {
            base.to_string()
        } else if base.ends_with("/v1") {
            format!("{}/chat/completions", base)
        } else {
            // ğŸ›¡ï¸ ä¿®å¤ï¼šå¦‚æœä¸åŒ…å« v1ï¼Œè‡ªåŠ¨è¡¥å…¨ /v1/chat/completionsï¼Œä¸å‰ç«¯æµ‹è¯•ä¿æŒä¸€è‡´
            // è¿™è§£å†³äº†ç±»ä¼¼ https://api.ohmygpt.com è¿™ç§ BaseURL å¯¼è‡´çš„æµ‹è¯•é€šè¿‡ä½†å¯¹è¯å¤±è´¥çš„é—®é¢˜
            format!("{}/v1/chat/completions", base)
        }
    };

    // println!("ğŸ”— æœ€ç»ˆå¯¹è¯è¯·æ±‚åœ°å€: {}", url);

    let response = client
        .post(&url)
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&payload)
        .send()
        .await
        .map_err(|e| {
            println!("âŒ è¯·æ±‚å¤±è´¥: {}", e);
            e.to_string()
        })?;

    if !response.status().is_success() {
        let status = response.status();
        let err_body = response.text().await.unwrap_or_default();
        println!("âŒ API è¿”å›é”™è¯¯ ({}): {}", status, err_body);
        return Err(format!("API Error: {}", err_body));
    }

    if !stream.unwrap_or(true) {
        // --- ğŸ›‘ éæµå¼å“åº”å¤„ç† ---
        let json: Value = response.json().await.map_err(|e| e.to_string())?;
        // println!("ğŸ“© æ”¶åˆ°éæµå¼å“åº”: {:?}", json); // ç§»é™¤å†—ä½™
        let choice = &json["choices"][0];
        let message = &choice["message"];

        if let Some(content) = message["content"].as_str() {
            on_event
                .send(format!("c:{}", content))
                .map_err(|e| e.to_string())?;
        }

        if let Some(reasoning) = message["reasoning_content"].as_str() {
            on_event
                .send(format!("r:{}", reasoning))
                .map_err(|e| e.to_string())?;
        }

        return Ok(());
    }

    // --- ğŸŒŠ æµå¼å“åº”å¤„ç† ---
    let mut stream = response.bytes_stream();
    let mut buffer = String::new();
    let mut ttft_logged = false;
    let start_gen = std::time::Instant::now();

    while let Some(chunk) = stream.next().await {
        if state.stop_flag.load(Ordering::Relaxed) {
            println!("âš¡ [åç«¯ä¿¡å·] ç”¨æˆ·æ‰“æ–­äº†ç”Ÿæˆ");
            break;
        }

        let chunk = chunk.map_err(|e| e.to_string())?;
        let chunk_str = String::from_utf8_lossy(&chunk);
        buffer.push_str(&chunk_str);

        while let Some(newline_idx) = buffer.find('\n') {
            let line = buffer.drain(..=newline_idx).collect::<String>();
            let line = line.trim();

            if line.is_empty() || line == "data: [DONE]" {
                if line == "data: [DONE]" {
                    return Ok(());
                }
                continue;
            }

            if let Some(data) = line.strip_prefix("data: ") {
                if let Ok(json) = serde_json::from_str::<serde_json::Value>(data) {
                    if let Some(choices) = json["choices"].as_array() {
                        if choices.is_empty() {
                            continue;
                        }
                        let choice = &choices[0];
                        let delta = &choice["delta"];

                        if let Some(content) = delta["content"].as_str() {
                            if !ttft_logged {
                                println!("â±ï¸ [æ€§èƒ½] AI å“åº” TTFT: {:?}", start_gen.elapsed());
                                ttft_logged = true;
                            }
                            on_event
                                .send(format!("c:{}", content))
                                .map_err(|e| e.to_string())?;
                        }

                        if let Some(reasoning) = delta["reasoning_content"].as_str() {
                            on_event
                                .send(format!("r:{}", reasoning))
                                .map_err(|e| e.to_string())?;
                        }
                    } else if let Some(err) = json["error"].as_object() {
                        println!("âŒ æµä¸­å‘ç°é”™è¯¯: {:?}", err);
                        return Err(format!("Stream Error: {:?}", err));
                    }
                }
            }
        }
    }

    // println!("âœ… AI ç”Ÿæˆä»»åŠ¡å·²å½»åº•é‡Šæ”¾");
    Ok(())
}

// --- â¬‡ï¸ Gemini Native ç›¸å…³ç»“æ„å’Œå®ç° â¬‡ï¸ ---

#[derive(Serialize)]
struct GeminiPart {
    text: Option<String>,
}

#[derive(Serialize)]
struct GeminiContent {
    role: String,
    parts: Vec<GeminiPart>,
}

#[derive(Serialize)]
struct GeminiRequest {
    contents: Vec<GeminiContent>,
}

async fn handle_gemini_native(
    api_key: String,
    base_url: String,
    model: String,
    messages: Vec<Message>,
    state: State<'_, crate::GoleState>,
    on_event: Channel<String>,
    stream: bool,
    client: &reqwest::Client,
) -> Result<(), String> {
    // 1. è½¬æ¢æ¶ˆæ¯æ ¼å¼
    let contents: Vec<GeminiContent> = messages
        .into_iter()
        .map(|m| {
            let role = if m.role == "user" { "user" } else { "model" };
            GeminiContent {
                role: role.to_string(),
                parts: vec![GeminiPart {
                    text: Some(m.content),
                }],
            }
        })
        .collect();

    let payload = GeminiRequest { contents };

    // 2. æ„é€  URL
    let mode = if stream {
        "streamGenerateContent"
    } else {
        "generateContent"
    };

    let url = format!(
        "{}/v1beta/models/{}:{}?key={}",
        base_url.trim_end_matches('/'),
        model,
        mode,
        api_key
    );

    println!("ğŸš€ [Native Gemini] è¯·æ±‚åœ°å€ (stream: {}): {}", stream, url);

    let response = client
        .post(&url)
        .header("Content-Type", "application/json")
        .json(&payload)
        .send()
        .await
        .map_err(|e| format!("Gemini ç½‘ç»œè¯·æ±‚å¤±è´¥: {}", e))?;

    if !response.status().is_success() {
        let status = response.status();
        let err_text = response.text().await.unwrap_or_default();
        // The original instruction had a syntactically incorrect line here.
        // Assuming the intent was to return the error.
        return Err(format!("Gemini API é”™è¯¯ (çŠ¶æ€ç  {}): {}", status, err_text));
    }

    if !stream {
        // --- ğŸ›‘ éæµå¼å¤„ç† ---
        let json: Value = response.json().await.map_err(|e| e.to_string())?;
        if let Some(candidates) = json["candidates"].as_array() {
            if let Some(candidate) = candidates.first() {
                if let Some(parts) = candidate["content"]["parts"].as_array() {
                    for part in parts {
                        if let Some(text) = part["text"].as_str() {
                            on_event
                                .send(format!("c:{}", text))
                                .map_err(|e| e.to_string())?;
                        }
                    }
                }
            }
        }
        return Ok(());
    }

    // --- ğŸŒŠ æµå¼å¤„ç† ---
    let mut stream = response.bytes_stream();
    let mut buffer = String::new();
    let mut ttft_logged = false;
    let start_gen = std::time::Instant::now();

    while let Some(chunk) = stream.next().await {
        if state.stop_flag.load(Ordering::Relaxed) {
            break;
        }

        let chunk = chunk.map_err(|e| e.to_string())?;
        buffer.push_str(&String::from_utf8_lossy(&chunk));

        // Gemini çš„ stream æ•°æ®æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ª JSON å¯¹è±¡çš„æ•°ç»„ï¼Œæ ¼å¼å¤§è‡´ä¸º [ {...}, {...} ]
        // è¿™é‡Œå°è¯•è§£æå®Œæ•´çš„ JSON å¯¹è±¡å—
        while let Some(start_idx) = buffer.find('{') {
            let mut depth = 0;
            let mut end_idx = None;
            let bytes = buffer.as_bytes();

            for i in start_idx..bytes.len() {
                if bytes[i] == b'{' {
                    depth += 1;
                } else if bytes[i] == b'}' {
                    if depth > 0 {
                        depth -= 1;
                        if depth == 0 {
                            end_idx = Some(i);
                            break;
                        }
                    }
                }
            }

            if let Some(end) = end_idx {
                let json_str = &buffer[start_idx..=end];
                if let Ok(json) = serde_json::from_str::<Value>(json_str) {
                    // è§£æ candidates[0].content.parts[0].text
                    if let Some(parts) = json["candidates"][0]["content"]["parts"].as_array() {
                        for part in parts {
                            if let Some(text) = part["text"].as_str() {
                                if !ttft_logged {
                                    println!(
                                        "â±ï¸ [æ€§èƒ½] AI (Gemini) å“åº” TTFT: {:?}",
                                        start_gen.elapsed()
                                    );
                                    ttft_logged = true;
                                }
                                on_event
                                    .send(format!("c:{}", text))
                                    .map_err(|e| e.to_string())?;
                            }
                        }
                    }
                }
                buffer.drain(..=end);
            } else {
                break; // ç­‰å¾…æ›´å¤šæ•°æ®
            }
        }
    }

    Ok(())
}
