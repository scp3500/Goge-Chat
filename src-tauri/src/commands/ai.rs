use crate::commands::config_cmd;
use crate::memory::processor::{get_relevant_context, MemoryState};
use crate::models::{ChatRequest, Message};
use futures_util::StreamExt;
use serde::Serialize;
use serde_json::{json, Value};
use std::sync::atomic::Ordering;
use std::sync::Arc;
use tauri::{ipc::Channel, AppHandle, Emitter, State};
use tokio::sync::RwLock;

#[tauri::command]
pub async fn ask_ai(
    app: AppHandle,
    state: State<'_, crate::GoleState>,
    memory_state: State<'_, Arc<RwLock<MemoryState>>>,
    msg: Vec<Message>,
    on_event: Channel<String>,
    temperature: Option<f32>,
    max_tokens: Option<u32>,
    stream: Option<bool>,
    // ğŸŸ¢ æ–°å¢ï¼šå…è®¸å‰ç«¯æ˜¾å¼ä¼ å…¥å½“å‰ç»˜ç”»çš„ provider å’Œ model
    explicit_provider_id: Option<String>,
    explicit_model_id: Option<String>,
    client: State<'_, reqwest::Client>,
) -> Result<(), String> {
    // --- ğŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šå¹¶è¡Œæ‰§è¡Œé¢„å¤„ç†ä»»åŠ¡ ---
    let start_total = std::time::Instant::now(); // â±ï¸ å¼€å§‹è®¡æ—¶
    let config = config_cmd::load_config(app.clone()).await?;
    let config_load_time = start_total.elapsed();

    // 2. ç¡®å®šå½“å‰ä½¿ç”¨çš„æ¨¡å‹å’Œæä¾›å•†
    // ä¼˜å…ˆä½¿ç”¨æ˜¾å¼ä¼ å…¥çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰ï¼ˆæ—§ç‰ˆå‰ç«¯ï¼‰ï¼Œåˆ™å›é€€åˆ°å…¨å±€é…ç½®
    let selected_model = explicit_model_id.unwrap_or(config.selected_model_id.clone());
    let selected_provider_id = explicit_provider_id.unwrap_or(config.default_provider_id.clone());

    // ä» providers æ•°ç»„ä¸­æ‰¾åˆ°å½“å‰é€‰ä¸­çš„æä¾›å•†é…ç½®
    let providers = config
        .providers
        .as_array()
        .ok_or("é…ç½®é”™è¯¯ï¼šæ— æ³•è¯»å–æä¾›å•†åˆ—è¡¨")?;
    let provider_config = providers
        .iter()
        .find(|p| p["id"].as_str() == Some(&selected_provider_id))
        .ok_or(format!("æ‰¾ä¸åˆ°æä¾›å•†é…ç½®: {}", selected_provider_id))?;

    let api_key = provider_config["apiKey"].as_str().unwrap_or("").to_string();
    let base_url = provider_config["baseUrl"]
        .as_str()
        .unwrap_or("https://api.deepseek.com")
        .to_string();

    if api_key.trim().is_empty() {
        return Err(format!(
            "{} çš„ API Key æœªé…ç½®ï¼Œè¯·å‰å¾€è®¾ç½®é¡µé¢å¡«å†™",
            provider_config["name"].as_str().unwrap_or("è¯¥æä¾›å•†")
        ));
    }

    let messages = msg;

    // æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶ä½¿ç”¨æ¨ç† (å¦‚æœç”¨æˆ·æ‰‹åŠ¨è¾“å…¥äº† [REASON] æ ‡è®°)
    let has_reason_tag = messages
        .iter()
        .any(|m| m.role == "user" && m.content.contains("[REASON]"));

    let model = if has_reason_tag {
        // å¦‚æœæœ‰æ ‡è®°ä¸”æ˜¯ DeepSeekï¼Œåˆ‡æ¢åˆ° reasoner
        if selected_provider_id == "deepseek" {
            "deepseek-reasoner".to_string()
        } else {
            selected_model
        }
    } else {
        selected_model
    };

    // --- ğŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šå¹¶è¡Œæ‰§è¡Œ[æœç´¢]å’Œ[è®°å¿†]ä»»åŠ¡ ---
    let messages_for_search = messages.clone();
    let search_instance_url = config.search_instance_url.clone();

    // æå–è®°å¿†æ£€ç´¢å‚æ•°
    let last_user_msg = messages.iter().rev().find(|m| m.role == "user");
    let query = last_user_msg.map(|m| m.content.clone()).unwrap_or_default();
    let mode = last_user_msg
        .and_then(|m| m.mode.as_deref())
        .unwrap_or("Standard")
        .to_string();
    let role_id = last_user_msg
        .and_then(|m| m.role_id.as_deref())
        .unwrap_or("default")
        .to_string();

    // åˆ›å»ºå¹¶å‘ä»»åŠ¡
    let memory_state_inner = memory_state.inner().clone();
    let memory_task =
        get_relevant_context_parallel(app.clone(), memory_state_inner, query, mode, role_id);
    let search_task = handle_search_parallel(app.clone(), messages_for_search, search_instance_url);
    // å¹¶è¡Œç­‰å¾…
    let (search_res, memory_res): (Result<Vec<Message>, String>, Result<Option<String>, String>) =
        tokio::join!(search_task, memory_task);

    // å¤„ç†æœç´¢ç»“æœ
    let mut clean_msgs = search_res?;

    // å¤„ç†è®°å¿†ç»“æœå¹¶æ³¨å…¥
    if let Ok(Some(context)) = memory_res {
        if let Some(sys_msg) = clean_msgs.iter_mut().find(|m| m.role == "system") {
            sys_msg.content = format!("{}\n\n{}", context, sys_msg.content);
        } else {
            clean_msgs.insert(
                0,
                Message {
                    id: None,
                    model: None,
                    role: "system".to_string(),
                    content: context,
                    reasoning_content: None,
                    file_metadata: None,
                    search_metadata: None,
                    provider: None,
                    mode: None,
                    role_id: None,
                },
            );
        }
    }

    let temperature =
        temperature.or_else(|| provider_config["temperature"].as_f64().map(|f| f as f32));
    let max_tokens = max_tokens.or_else(|| provider_config["maxTokens"].as_u64().map(|u| u as u32));

    // --- â¬‡ï¸ Google Gemini Native æ”¯æŒ â¬‡ï¸ ---
    if selected_provider_id == "gemini" {
        return handle_gemini_native(
            api_key,
            base_url,
            model,
            clean_msgs,
            state,
            on_event,
            stream.unwrap_or(true),
            &client,
            start_total,
        )
        .await;
    }
    // --- â¬†ï¸ Google Gemini Native æ”¯æŒ â¬†ï¸ ---

    let payload = ChatRequest {
        model: model.to_string(),
        messages: clean_msgs,
        stream: stream.unwrap_or(true),
        temperature,
        max_tokens,
    };

    let disable_url_suffix = provider_config["disableUrlSuffix"]
        .as_bool()
        .unwrap_or(false);

    let url = if disable_url_suffix {
        base_url.clone()
    } else {
        let base = base_url.trim_end_matches('/');
        if base.ends_with("/chat/completions") {
            base.to_string()
        } else if base.ends_with("/v1") {
            format!("{}/chat/completions", base)
        } else {
            // ğŸ›¡ï¸ ä¿®å¤ï¼šå¦‚æœä¸åŒ…å« v1ï¼Œè‡ªåŠ¨è¡¥å…¨ /v1/chat/completionsï¼Œä¸å‰ç«¯æµ‹è¯•ä¿æŒä¸€è‡´
            // è¿™è§£å†³äº†ç±»ä¼¼ https://api.ohmygpt.com è¿™ç§ BaseURL å¯¼è‡´çš„æµ‹è¯•é€šè¿‡ä½†å¯¹è¯å¤±è´¥çš„é—®é¢˜
            format!("{}/v1/chat/completions", base)
        }
    };

    // println!("ğŸ”— æœ€ç»ˆå¯¹è¯è¯·æ±‚åœ°å€: {}", url);

    let response = client
        .post(&url)
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&payload)
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if !response.status().is_success() {
        let err_body = response.text().await.unwrap_or_default();
        return Err(format!("API Error: {}", err_body));
    }

    if !stream.unwrap_or(true) {
        // --- ğŸ›‘ éæµå¼å“åº”å¤„ç† ---
        let content =
            crate::ai_utils::call_ai_backend(&client, &api_key, &base_url, &payload).await?;

        on_event
            .send(format!("c:{}", content))
            .map_err(|e| e.to_string())?;

        return Ok(());
    }

    // --- ğŸŒŠ æµå¼å“åº”å¤„ç† ---
    let mut stream = response.bytes_stream();
    let mut buffer = String::new();
    let mut ttft_logged = false;

    while let Some(chunk) = stream.next().await {
        if state.stop_flag.load(Ordering::Relaxed) {
            break;
        }

        let chunk = chunk.map_err(|e| e.to_string())?;
        let chunk_str = String::from_utf8_lossy(&chunk);
        buffer.push_str(&chunk_str);

        while let Some(newline_idx) = buffer.find('\n') {
            let line = buffer.drain(..=newline_idx).collect::<String>();
            let line = line.trim();

            if line.is_empty() || line == "data: [DONE]" {
                if line == "data: [DONE]" {
                    return Ok(());
                }
                continue;
            }

            if let Some(data) = line.strip_prefix("data: ") {
                if let Ok(json) = serde_json::from_str::<serde_json::Value>(data) {
                    if let Some(choices) = json["choices"].as_array() {
                        if choices.is_empty() {
                            continue;
                        }
                        let choice = &choices[0];
                        let delta = &choice["delta"];

                        if let Some(content) = delta["content"].as_str() {
                            if !ttft_logged {
                                // ğŸŸ¢ ç›‘æµ‹ï¼šæ€»è€—æ—¶ï¼ˆåŒ…å«åŠ è½½é…ç½®ã€æ£€ç´¢è®°å¿†ã€ç½‘è·¯å¾€è¿”ï¼‰
                                println!(
                                    "â±ï¸ [æ€§èƒ½] é¦–å­—æ€»å“åº” (é…ç½®åŠ è½½ {}ms + å…¶ä»– {}ms): {:?}",
                                    config_load_time.as_millis(),
                                    (start_total.elapsed() - config_load_time).as_millis(),
                                    start_total.elapsed()
                                );
                                ttft_logged = true;
                            }
                            on_event
                                .send(format!("c:{}", content))
                                .map_err(|e| e.to_string())?;
                        }

                        if let Some(reasoning) = delta["reasoning_content"]
                            .as_str()
                            .or_else(|| delta["reasoning"].as_str())
                            .or_else(|| delta["thought"].as_str())
                        {
                            on_event
                                .send(format!("r:{}", reasoning))
                                .map_err(|e| e.to_string())?;
                        }
                    } else if let Some(err) = json["error"].as_object() {
                        return Err(format!("Stream Error: {:?}", err));
                    }
                }
            }
        }
    }

    // println!("âœ… AI ç”Ÿæˆä»»åŠ¡å·²å½»åº•é‡Šæ”¾");
    Ok(())
}

// --- â¬‡ï¸ Gemini Native ç›¸å…³ç»“æ„å’Œå®ç° â¬‡ï¸ ---

#[derive(Serialize)]
struct GeminiPart {
    text: Option<String>,
}

#[derive(Serialize)]
struct GeminiContent {
    role: String,
    parts: Vec<GeminiPart>,
}

#[derive(Serialize)]
struct GeminiRequest {
    contents: Vec<GeminiContent>,
}

async fn handle_gemini_native(
    api_key: String,
    base_url: String,
    model: String,
    messages: Vec<Message>,
    state: State<'_, crate::GoleState>,
    on_event: Channel<String>,
    stream: bool,
    client: &reqwest::Client,
    start_total: std::time::Instant,
) -> Result<(), String> {
    if !stream {
        // --- ğŸ›‘ éæµå¼å¤„ç† ---
        let content = crate::ai_utils::call_gemini_backend(
            client,
            &api_key,
            &base_url,
            &model,
            messages.clone(),
        )
        .await?;

        on_event
            .send(format!("c:{}", content))
            .map_err(|e| e.to_string())?;

        return Ok(());
    }

    // --- ğŸŒŠ æµå¼å¤„ç† ---
    // 1. è½¬æ¢æ¶ˆæ¯æ ¼å¼
    let contents: Vec<GeminiContent> = messages
        .into_iter()
        .map(|m| {
            let role = if m.role == "user" { "user" } else { "model" };
            GeminiContent {
                role: role.to_string(),
                parts: vec![GeminiPart {
                    text: Some(m.content),
                }],
            }
        })
        .collect();

    let payload = GeminiRequest { contents };

    // 2. æ„é€  URL
    let mode = "streamGenerateContent";

    let url = format!(
        "{}/v1beta/models/{}:{}?key={}",
        base_url.trim_end_matches('/'),
        model,
        mode,
        api_key
    );

    let response = client
        .post(&url)
        .header("Content-Type", "application/json")
        .json(&payload)
        .send()
        .await
        .map_err(|e| format!("Gemini ç½‘ç»œè¯·æ±‚å¤±è´¥: {}", e))?;

    if !response.status().is_success() {
        let status = response.status();
        let err_text = response.text().await.unwrap_or_default();
        return Err(format!("Gemini API é”™è¯¯ (çŠ¶æ€ç  {}): {}", status, err_text));
    }

    // --- ğŸŒŠ æµå¼å¤„ç† ---
    let mut stream = response.bytes_stream();
    let mut buffer = String::new();
    let mut ttft_logged = false;

    while let Some(chunk) = stream.next().await {
        if state.stop_flag.load(Ordering::Relaxed) {
            break;
        }

        let chunk = chunk.map_err(|e| e.to_string())?;
        buffer.push_str(&String::from_utf8_lossy(&chunk));

        // Gemini çš„ stream æ•°æ®æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ª JSON å¯¹è±¡çš„æ•°ç»„ï¼Œæ ¼å¼å¤§è‡´ä¸º [ {...}, {...} ]
        // è¿™é‡Œå°è¯•è§£æå®Œæ•´çš„ JSON å¯¹è±¡å—
        while let Some(start_idx) = buffer.find('{') {
            let mut depth = 0;
            let mut end_idx = None;
            let bytes = buffer.as_bytes();

            for i in start_idx..bytes.len() {
                if bytes[i] == b'{' {
                    depth += 1;
                } else if bytes[i] == b'}' {
                    if depth > 0 {
                        depth -= 1;
                        if depth == 0 {
                            end_idx = Some(i);
                            break;
                        }
                    }
                }
            }

            if let Some(end) = end_idx {
                let json_str = &buffer[start_idx..=end];
                if let Ok(json) = serde_json::from_str::<Value>(json_str) {
                    // è§£æ candidates[0].content.parts[0].text
                    if let Some(parts) = json["candidates"][0]["content"]["parts"].as_array() {
                        for part in parts {
                            if let Some(text) = part["text"].as_str() {
                                if !ttft_logged {
                                    // ğŸŸ¢ ç›‘æµ‹ï¼šä»ç”¨æˆ·è¾“å…¥åˆ°æµå¼è¾“å‡ºé¦–å­—çš„æ€§èƒ½è€—æ—¶ (Gemini)
                                    println!(
                                        "â±ï¸ [æ€§èƒ½] Gemini æ¨¡å¼é¦–å­—æ€»è€—æ—¶ (ä»è¾“å…¥): {:?}",
                                        start_total.elapsed()
                                    );
                                    ttft_logged = true;
                                }
                                on_event
                                    .send(format!("c:{}", text))
                                    .map_err(|e| e.to_string())?;
                            }
                        }
                    }
                }
                buffer.drain(..=end);
            } else {
                break; // ç­‰å¾…æ›´å¤šæ•°æ®
            }
        }
    }

    Ok(())
}

#[tauri::command]
pub async fn discover_models_raw(
    url: String,
    api_key: Option<String>,
    headers_map: Option<std::collections::HashMap<String, String>>,
    client: State<'_, reqwest::Client>,
) -> Result<Value, String> {
    let mut request = client.get(&url);

    if let Some(key) = api_key {
        if !key.is_empty() {
            request = request.header("Authorization", format!("Bearer {}", key));
        }
    }

    if let Some(h) = headers_map {
        for (k, v) in h {
            request = request.header(k, v);
        }
    }

    let response = request
        .send()
        .await
        .map_err(|e| format!("Network error: {}", e))?;

    if !response.status().is_success() {
        let status = response.status();
        let err_text = response.text().await.unwrap_or_default();
        return Err(format!("API Error ({}): {}", status, err_text));
    }

    let data = response
        .json::<Value>()
        .await
        .map_err(|e| format!("JSON parse error: {}", e))?;
    Ok(data)
}

// --- ğŸš€ åŠ©æ‰‹å‡½æ•°ï¼šå¹¶è¡Œå¤„ç†æœç´¢é€»è¾‘ ---
async fn handle_search_parallel(
    app: AppHandle,
    messages: Vec<Message>,
    search_instance_url: String,
) -> Result<Vec<Message>, String> {
    let mut clean_msgs = messages.clone();

    // æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦æœ‰ [SEARCH]
    if let Some(m) = clean_msgs.last_mut() {
        if m.role == "user" && m.content.contains("[SEARCH]") {
            let (original_query, provider) = if m.content.contains("[SEARCH:") {
                let start = m.content.find("[SEARCH:").unwrap();
                let end = m.content[start..].find(']').unwrap() + start;
                let provider = &m.content[start + 8..end];
                let clean = m.content.replace(&m.content[start..=end], "");
                (clean, provider.to_string())
            } else {
                (m.content.replace("[SEARCH]", ""), "all".to_string())
            };

            // å‘é€æœç´¢å¼€å§‹äº‹ä»¶
            let _ = app.emit(
                "search-status",
                json!({ "status": "searching", "query": original_query }),
            );

            match crate::commands::search::perform_search(
                &search_instance_url,
                &original_query,
                &provider,
            )
            .await
            {
                Ok(results) => {
                    // å‘é€æœç´¢ç»“æœäº‹ä»¶
                    let _ = app.emit(
                        "search-status",
                        json!({ "status": "done", "results": results }),
                    );

                    let mut context = String::from("ã€è”ç½‘æœç´¢å‚è€ƒèµ„æ–™ã€‘\n");
                    for (i, res) in results.iter().enumerate() {
                        context.push_str(&format!(
                            "{}. {}\n   é“¾æ¥: {}\n   å†…å®¹: {}\n\n",
                            i + 1,
                            res.title,
                            res.url,
                            res.snippet
                        ));
                    }

                    m.content = format!(
                        "ç”¨æˆ·åŸå§‹é—®é¢˜: {}\n\n{}\nè¯·åˆ†æä»¥ä¸Šæœç´¢ç»“æœï¼Œç»“åˆä½ çš„çŸ¥è¯†ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ä¸”æœ€æ–°çš„å›ç­”ã€‚",
                        original_query, context
                    );
                }
                Err(e) => {
                    let _ = app.emit("search-status", json!({ "status": "error", "message": e }));
                }
            }
        }
    }

    Ok(clean_msgs)
}

// --- ğŸš€ åŠ©æ‰‹å‡½æ•°ï¼šå¹¶è¡Œå¤„ç†è®°å¿†æ£€ç´¢é€»è¾‘ ---
async fn get_relevant_context_parallel(
    app: AppHandle,
    memory_state: Arc<RwLock<MemoryState>>,
    query: String,
    mode: String,
    role_id: String,
) -> Result<Option<String>, String> {
    if query.is_empty() {
        return Ok(None);
    }

    // å‘é€è®°å¿†æ£€ç´¢å¼€å§‹äº‹ä»¶
    let _ = app.emit(
        "memory-status",
        json!({ "status": "searching", "query": query }),
    );
    let start_time = std::time::Instant::now();

    // æ‰§è¡Œè®°å¿†æ£€ç´¢
    let context = get_relevant_context(memory_state, &query, &mode, &role_id).await?;

    let duration = start_time.elapsed().as_millis();

    if !context.is_empty() {
        // å‘é€è®°å¿†æ£€ç´¢å®Œæˆäº‹ä»¶
        let _ = app.emit(
            "memory-status",
            json!({ "status": "done", "duration": duration, "has_context": true }),
        );
        Ok(Some(context))
    } else {
        // å‘é€è®°å¿†æ£€ç´¢å®Œæˆäº‹ä»¶ (æ— ç»“æœ)
        let _ = app.emit(
            "memory-status",
            json!({ "status": "done", "duration": duration, "has_context": false }),
        );
        Ok(None)
    }
}
