use crate::behavior_engine::{BehaviorEngine, SessionContext};
use crate::behavior_scheduler::MessageScheduler;
use crate::commands::config_cmd;
use crate::models::{ChatRequest, Message};
use crate::social_db::SocialDbState;
use futures_util::StreamExt;
use std::sync::Arc;
use tauri::{command, AppHandle, Emitter, Manager, State};

/// å‘é€æ²‰æµ¸å¼ç¤¾äº¤æ¶ˆæ¯
///
/// å¦‚æœæ²‰æµ¸å¼æ¨¡å¼å¯ç”¨,å°†ä½¿ç”¨è¡Œä¸ºå¼•æ“ç”Ÿæˆè¡Œä¸ºé“¾å¹¶å¼‚æ­¥æ‰§è¡Œ
/// å¦åˆ™ç›´æ¥ä¿å­˜æ¶ˆæ¯
#[command]
pub async fn send_social_message_immersive(
    app: AppHandle,
    state: State<'_, crate::GoleState>, // âœ¨ æ³¨å…¥å…¨å±€ä¸­æ–­æ ‡å¿—
    scheduler: State<'_, Arc<MessageScheduler>>,
    session_id: i64,
    contact_id: i64,
    _content: String,
) -> Result<(), String> {
    // 1. æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´ (ç”¨äº IdleMonitor è¿½è¸ª)
    scheduler.touch_session(session_id).await;

    // 2. åŠ è½½é…ç½®
    let config = config_cmd::load_config(app.clone()).await?;
    let settings = config.immersive_mode;

    // 3. æ£€æŸ¥è¡Œä¸ºæ¨¡æ‹Ÿæ˜¯å¦å¯ç”¨ (æ³¨æ„: è¿™é‡Œåªå†³å®šæ˜¯å¦å¯ç”¨å»¶è¿Ÿ/æ‹†åˆ†ç­‰è¡Œä¸º)
    // å³ä½¿å…³é—­äº†è¡Œä¸ºæ¨¡æ‹Ÿ,åªè¦åœ¨ç¤¾äº¤æ¨¡å¼ä¸‹,æˆ‘ä»¬ä»ç„¶è¦åœ¨è¿™é‡Œå¤„ç† AI è°ƒç”¨
    let is_behavior_enabled = settings.enabled;
    println!("[ç¤¾äº¤] è¡Œä¸ºå¯ç”¨: {}", is_behavior_enabled);

    // --- ğŸš€ ç¤¾äº¤æ¨¡å¼ (æ²‰æµ¸å¼) å¤„ç†é€»è¾‘ ---
    // æ³¨æ„: ç”¨æˆ·æ¶ˆæ¯å·²ç»ç”±å‰ç«¯ä¿å­˜,è¿™é‡Œä¸å†é‡å¤ä¿å­˜

    // 3. ğŸ§  çŠ¶æ€åˆ†æé›†æˆ
    let db_state: tauri::State<SocialDbState> = app.state();
    let mut session_context = SessionContext {
        session_id,
        contact_id,
        mood: None,
        busy_level: None,
        interest_level: None,
    };

    // å¢åŠ æ¶ˆæ¯è®¡æ•°
    let message_count =
        crate::social_db::increment_message_count(db_state.clone(), contact_id, session_id)?;

    println!("[ç¤¾äº¤] æ¶ˆæ¯è®¡æ•°: {}", message_count);

    // æ£€æŸ¥æ˜¯å¦å¯ç”¨çŠ¶æ€è¿½è¸ª
    if let Some(ref state_config) = settings.behaviors.character_state_config {
        if state_config.enabled {
            let analyzer = crate::character_state::StateAnalyzer::new();

            // æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘åˆ†æ
            let should_analyze = analyzer
                .should_analyze(contact_id, session_id, state_config, &db_state)
                .await?;

            if should_analyze {
                println!("[çŠ¶æ€] è§¦å‘åˆ†æ...");

                // è·å–æœ€è¿‘çš„æ¶ˆæ¯å†å² (åœ¨å•ç‹¬çš„ä½œç”¨åŸŸä¸­,ç¡®ä¿é”è¢«é‡Šæ”¾)
                let messages = {
                    let conn = db_state.0.lock().map_err(|e| e.to_string())?;
                    let mut stmt = conn
                        .prepare(
                            "SELECT role, content FROM social_messages 
                             WHERE contact_id = ?1 AND session_id = ?2 
                             ORDER BY created_at DESC LIMIT 20",
                        )
                        .map_err(|e| e.to_string())?;

                    let messages: Vec<(String, String)> = stmt
                        .query_map(rusqlite::params![contact_id, session_id], |row| {
                            Ok((row.get(0)?, row.get(1)?))
                        })
                        .map_err(|e| e.to_string())?
                        .collect::<Result<Vec<_>, _>>()
                        .map_err(|e| e.to_string())?;

                    messages
                };

                // æ‰§è¡ŒçŠ¶æ€åˆ†æ
                let analysis = analyzer
                    .analyze_state(contact_id, session_id, messages)
                    .await?;

                // ä¿å­˜åˆ†æç»“æœ
                crate::social_db::upsert_character_state(
                    db_state.clone(),
                    contact_id,
                    session_id,
                    analysis.mood.clone(),
                    analysis.busy_level,
                    analysis.interest_level,
                )?;

                // é‡ç½®æ¶ˆæ¯è®¡æ•°
                crate::social_db::reset_message_count(db_state.clone(), contact_id, session_id)?;

                // æ›´æ–°ä¸Šä¸‹æ–‡
                session_context.mood = Some(analysis.mood);
                session_context.busy_level = Some(analysis.busy_level);
                session_context.interest_level = Some(analysis.interest_level);

                println!("[çŠ¶æ€] åˆ†æå·²ä¿å­˜");
            } else {
                // ä»æ•°æ®åº“åŠ è½½ç°æœ‰çŠ¶æ€
                if let Some(state) =
                    crate::social_db::get_character_state(db_state.clone(), contact_id, session_id)?
                {
                    session_context.mood =
                        state.get("mood").and_then(|v| v.as_str()).map(String::from);
                    session_context.busy_level = state
                        .get("busyLevel")
                        .and_then(|v| v.as_f64())
                        .map(|f| f as f32);
                    session_context.interest_level = state
                        .get("interestLevel")
                        .and_then(|v| v.as_f64())
                        .map(|f| f as f32);

                    println!(
                        "[çŠ¶æ€] åŠ è½½ç¼“å­˜: å¿ƒæƒ…={:?}, å¿™ç¢Œ={:?}, å…´è¶£={:?}",
                        session_context.mood,
                        session_context.busy_level,
                        session_context.interest_level
                    );
                }
            }
        }
    }

    // 5. ğŸ¤– è°ƒç”¨ AI è·å–å›ç­” (å†…éƒ¨æµå¼æ”¶é›†)
    println!("[AI] [å¼€å§‹] è¯·æ±‚å“åº”...");

    // A. è·å–å¯¹è¯å†å² (20æ¡)
    let mut history = {
        let conn = db_state.0.lock().map_err(|e| e.to_string())?;
        let mut stmt = conn
            .prepare(
                "SELECT role, content FROM social_messages 
                 WHERE session_id = ?1 
                 ORDER BY id DESC LIMIT 21", // åŒ…å«åˆšåˆšä¿å­˜çš„é‚£æ¡
            )
            .map_err(|e| e.to_string())?;

        let messages: Vec<Message> = stmt
            .query_map(rusqlite::params![session_id], |row| {
                Ok(Message {
                    id: None,
                    model: None,
                    role: row.get(0)?,
                    content: row.get(1)?,
                    reasoning_content: None,
                    file_metadata: None,
                    search_metadata: None,
                    provider: None,
                    mode: None,
                    role_id: None,
                })
            })
            .map_err(|e| e.to_string())?
            .collect::<Result<Vec<_>, _>>()
            .map_err(|e| e.to_string())?;

        let mut history = messages;
        history.reverse();
        history
    };

    // A.2 æ³¨å…¥ç³»ç»Ÿæç¤ºè¯ (System Prompt)
    // ç¤¾äº¤æ¨¡å¼ä¸‹å¿…é¡»æ³¨å…¥è§’è‰²çš„è®¾å®š,å¦åˆ™ AI ä¸çŸ¥é“è‡ªå·±æ˜¯è°
    let mut contact_provider = None;
    let mut contact_model = None;

    {
        let conn = db_state.0.lock().map_err(|e| e.to_string())?;
        let contact_info: Result<(Option<String>, Option<String>, Option<String>), _> = conn
            .query_row(
                "SELECT prompt, provider, model FROM contacts WHERE id = ?1",
                rusqlite::params![contact_id],
                |row| Ok((row.get(0)?, row.get(1)?, row.get(2)?)),
            );

        if let Ok((prompt, provider, model)) = contact_info {
            contact_provider = provider;
            contact_model = model;

            let final_prompt = if let Some(p) = prompt {
                if !p.trim().is_empty() {
                    Some(p)
                } else {
                    None
                }
            } else {
                None
            };

            // å¦‚æœè”ç³»äººæ²¡æœ‰æç¤ºè¯, å°è¯•ä»å…¨å±€é¢„è®¾ä¸­è·å–
            let prompt_to_inject = if let Some(p) = final_prompt {
                Some(p)
            } else {
                // è¯»å–å…¨å±€é¢„è®¾
                let global_preset_id = &config.global_preset_id;
                let presets = config.presets.as_array();
                presets
                    .and_then(|arr| {
                        arr.iter()
                            .find(|p| p["id"].as_str() == Some(global_preset_id))
                    })
                    .and_then(|p| p["systemPrompt"].as_str())
                    .map(|s| s.to_string())
            };

            if let Some(prompt) = prompt_to_inject {
                if !prompt.trim().is_empty() {
                    // å°†ç³»ç»Ÿæç¤ºè¯æ’å…¥åˆ°å†å²è®°å½•çš„æœ€å‰é¢
                    history.insert(
                        0,
                        Message {
                            id: None,
                            model: None,
                            role: "system".to_string(),
                            content: prompt,
                            reasoning_content: None,
                            file_metadata: None,
                            search_metadata: None,
                            provider: None,
                            mode: None,
                            role_id: None,
                        },
                    );
                    // println!("[Social] Injected system prompt");
                }
            }
        }
    }

    // B. è·å–é…ç½® (ä¼˜å…ˆä½¿ç”¨è”ç³»äººé…ç½®)
    let provider_id = contact_provider.unwrap_or_else(|| config.default_provider_id.clone());
    let model = contact_model.unwrap_or_else(|| config.selected_model_id.clone());

    println!("[AI] æä¾›å•†: {}, æ¨¡å‹: {}", provider_id, model);

    let providers = config.providers.as_array().ok_or("æ— æ³•è¯»å–æä¾›å•†åˆ—è¡¨")?;
    let provider_config = providers
        .iter()
        .find(|p| p["id"].as_str() == Some(&provider_id))
        .ok_or(format!("æ‰¾ä¸åˆ°æä¾›å•†é…ç½®: {}", provider_id))?;

    let api_key = provider_config["apiKey"].as_str().unwrap_or_default();
    let base_url = provider_config["baseUrl"].as_str().unwrap_or_default();

    // C. æ‰§è¡Œ AI è°ƒç”¨ (å†…éƒ¨æµå¼å¤„ç†)
    // C. æ‰§è¡Œ AI è°ƒç”¨ (å†…éƒ¨æµå¼å¤„ç† + âš¡ï¸ æè‡´ä¼˜åŒ–ï¼š20ms åˆæ‰¹åŒæ­¥)
    let client = app.state::<reqwest::Client>();
    let mut full_content = String::new();
    let mut pending_content = String::new();
    let mut last_emit = std::time::Instant::now();
    let mut emit_count = 0;

    // å®šä¹‰ä¸€ä¸ªç»Ÿä¸€çš„åˆæ‰¹å‘å°„å™¨
    let emit_chunk = |app: &AppHandle,
                          chunk: &str,
                          full: &mut String,
                          pending: &mut String,
                          last: &mut std::time::Instant,
                          count: &mut i32| {
        full.push_str(chunk);
        pending.push_str(chunk);

        // ç­–ç•¥ï¼šå‰ 5 æ¬¡ç«‹å³å‘é€ï¼Œåç»­ 20ms åˆæ‰¹
        if *count < 5 || last.elapsed().as_millis() >= 20 || pending.len() > 100 {
            if !pending.is_empty() {
                let _ = app.emit(
                    "social-streaming-chunk",
                    serde_json::json!({
                        "content": pending.clone(),
                        "isFirst": *count == 0
                    }),
                );
                pending.clear();
                *count += 1;
            }
            *last = std::time::Instant::now();
        }
    };

    if provider_id == "gemini" {
        crate::ai_utils::call_gemini_streaming(
            &client,
            api_key,
            base_url,
            &model,
            history,
            |chunk| {
                emit_chunk(
                    &app,
                    &chunk,
                    &mut full_content,
                    &mut pending_content,
                    &mut last_emit,
                    &mut emit_count,
                );
            },
        )
        .await?;
    } else {
        // OpenAI å…¼å®¹æµå¼å¤„ç†
        let payload = ChatRequest {
            model: model.clone(),
            messages: history,
            stream: true,
            temperature: Some(0.8),
            max_tokens: Some(1024),
        };

        let base = base_url.trim_end_matches('/');
        let url = if base.ends_with("/chat/completions") {
            base.to_string()
        } else if base.ends_with("/v1") {
            format!("{}/chat/completions", base)
        } else {
            format!("{}/v1/chat/completions", base)
        };

        let response = client
            .post(&url)
            .header("Authorization", format!("Bearer {}", api_key))
            .json(&payload)
            .send()
            .await
            .map_err(|e| format!("AI ç½‘ç»œè¯·æ±‚å¤±è´¥: {}", e))?;

        if !response.status().is_success() {
            let err_body = response.text().await.unwrap_or_default();
            return Err(format!("AI API é”™è¯¯: {}", err_body));
        }

        let mut stream = response.bytes_stream();
        let mut buffer = String::new();

        while let Some(chunk) = stream.next().await {
            // âœ¨ æ²‰æµ¸æ¨¡å¼ä¹Ÿæ”¯æŒç‰©ç†ä¸­æ–­
            if state.stop_flag.load(std::sync::atomic::Ordering::Relaxed) {
                return Ok(());
            }

            let chunk = chunk.map_err(|e| e.to_string())?;
            buffer.push_str(&String::from_utf8_lossy(&chunk));

            while let Some(newline_idx) = buffer.find('\n') {
                let line = buffer.drain(..=newline_idx).collect::<String>();
                let line = line.trim();

                if line.is_empty() || line == "data: [DONE]" {
                    continue;
                }

                if let Some(data) = line.strip_prefix("data: ") {
                    if let Ok(json) = serde_json::from_str::<serde_json::Value>(data) {
                        if let Some(content) = json["choices"][0]["delta"]["content"].as_str() {
                            emit_chunk(
                                &app,
                                content,
                                &mut full_content,
                                &mut pending_content,
                                &mut last_emit,
                                &mut emit_count,
                            );
                        }
                    }
                }
            }
        }
    }

    // ğŸš€ [æ”¶å°¾å·¥ä½œ]ï¼šå‘é€å‰©ä½™å†…å®¹å’Œç»“æŸæ ‡è®°
    if !pending_content.is_empty() {
        let _ = app.emit(
            "social-streaming-chunk",
            serde_json::json!({
                "content": pending_content,
                "isFirst": emit_count == 0
            }),
        );
    }

    let _ = app.emit(
        "social-streaming-chunk",
        serde_json::json!({
            "content": "",
            "isFirst": false,
            "isDone": true
        }),
    );

    let ai_response = full_content;

    println!("[AI] [å®Œæˆ] å“åº”æ”¶é›†å®Œæˆ ({} å­—ç¬¦)", ai_response.len());

    // 6. ä½¿ç”¨è¡Œä¸ºå¼•æ“ç”Ÿæˆè¡Œä¸ºé“¾ (é’ˆå¯¹ AI çš„å›ç­”)
    let engine = BehaviorEngine::new(settings.clone());
    let chain = engine.decide(&ai_response, &session_context);

    // 7. å¼‚æ­¥æ‰§è¡Œè¡Œä¸ºé“¾
    scheduler
        .execute_behavior_chain(
            session_id,
            contact_id,
            chain,
            session_context,
            settings,
            app.clone(),
        )
        .await?;

    Ok(())
}

/// å–æ¶ˆæŒ‡å®šä¼šè¯çš„æ‰€æœ‰å¾…æ‰§è¡Œè¡Œä¸º
#[command]
pub async fn cancel_immersive_behaviors(
    scheduler: State<'_, Arc<MessageScheduler>>,
    session_id: i64,
) -> Result<(), String> {
    scheduler.cancel_session_behaviors(session_id).await;
    Ok(())
}

/// å–æ¶ˆæ‰€æœ‰æ´»è·ƒçš„æ²‰æµ¸å¼è¡Œä¸º
#[command]
pub async fn cancel_all_immersive_behaviors(
    scheduler: State<'_, Arc<MessageScheduler>>,
) -> Result<(), String> {
    scheduler.cancel_all_behaviors().await;
    Ok(())
}
